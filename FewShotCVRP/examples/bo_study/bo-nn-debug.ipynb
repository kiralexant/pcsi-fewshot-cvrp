{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203cb1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import FewShotCVRP.bo.bo_torch as bo_torch\n",
    "\n",
    "reload(bo_torch)\n",
    "\n",
    "snap = bo_torch.BayesianOptimizer.load_snapshot(\n",
    "    \"../outputs/2025-09-15-21h53m45s/per-instance-param-control/X-n101-k25/bo-final\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72615fdc",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv-cvrp (Python 3.10.16)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import rich\n",
    "\n",
    "print(rich.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae055bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bo_cfg = snap.experiment_config[\"bo\"]\n",
    "bo = bo_torch.BayesianOptimizer(\n",
    "    None,\n",
    "    f_batch=None,\n",
    "    bounds=snap.arrays[\"bounds\"],\n",
    "    n_init=int(bo_cfg[\"n_init\"]),\n",
    "    n_iter=int(bo_cfg[\"n_iter\"]),\n",
    "    sigma=float(bo_cfg[\"sigma\"]),\n",
    "    kernel=str(bo_cfg[\"kernel\"]),\n",
    "    kernel_isotropic=bool(bo_cfg[\"kernel_isotropic\"]),\n",
    "    use_input_normalize=bool(bo_cfg[\"use_input_normalize\"]),\n",
    "    normalize_y=bool(bo_cfg[\"normalize_y\"]),\n",
    "    doe_method=str(bo_cfg[\"doe_method\"]),\n",
    "    n_restarts_acq_opt=int(bo_cfg[\"n_restarts_acq_opt\"]),\n",
    "    suggestions_per_step=int(bo_cfg[\"suggestions_per_step\"]),\n",
    "    diversity_frac=float(bo_cfg[\"diversity_frac\"]),\n",
    "    random_state=snap.experiment_config[\"random_seed\"],\n",
    ")\n",
    "gp_model = bo._create_gp_model(\n",
    "    bo_torch._as_t(snap.arrays[\"X_\"], dtype=bo.dtype, device=bo.device),\n",
    "    bo_torch._as_t(snap.arrays[\"y_\"].reshape(-1, 1), dtype=bo.dtype, device=bo.device),\n",
    ")\n",
    "gp_model.load_state_dict(snap.gp)\n",
    "\n",
    "# snap.gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "a1308998",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(bo_torch)\n",
    "\n",
    "bo_cfg = snap.experiment_config[\"bo\"]\n",
    "bo = bo_torch.BayesianOptimizer(\n",
    "    None,\n",
    "    f_batch=None,\n",
    "    bounds=snap.arrays[\"bounds\"],\n",
    "    n_init=int(bo_cfg[\"n_init\"]),\n",
    "    n_iter=int(bo_cfg[\"n_iter\"]),\n",
    "    sigma=float(bo_cfg[\"sigma\"]),\n",
    "    kernel=str(bo_cfg[\"kernel\"]),\n",
    "    kernel_isotropic=bool(bo_cfg[\"kernel_isotropic\"]),\n",
    "    use_input_normalize=bool(bo_cfg[\"use_input_normalize\"]),\n",
    "    normalize_y=bool(bo_cfg[\"normalize_y\"]),\n",
    "    doe_method=str(bo_cfg[\"doe_method\"]),\n",
    "    n_restarts_acq_opt=int(bo_cfg[\"n_restarts_acq_opt\"]),\n",
    "    suggestions_per_step=int(bo_cfg[\"suggestions_per_step\"]),\n",
    "    diversity_frac=float(bo_cfg[\"diversity_frac\"]),\n",
    "    random_state=snap.experiment_config[\"random_seed\"],\n",
    ")\n",
    "bo.X_ = bo_torch._as_t(snap.arrays[\"X_\"], dtype=bo.dtype, device=bo.device)\n",
    "bo.y_ = bo_torch._as_t(snap.arrays[\"y_\"].reshape(-1, 1), dtype=bo.dtype, device=bo.device)\n",
    "# bo._fit_gp()\n",
    "\n",
    "# snap.gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "bb7b9ebc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BayesianOptimizer' object has no attribute 'X_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[282], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_gp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/antonovk/FewShotCVRP/FewShotCVRP/bo/bo_torch.py:271\u001b[0m, in \u001b[0;36m_fit_gp\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m     Yvar = _as_t(yvar_np, self.dtype, self.device)\n\u001b[1;32m    262\u001b[0m     model = SingleTaskGP(\n\u001b[1;32m    263\u001b[0m         train_X=X,\n\u001b[1;32m    264\u001b[0m         train_Y=Y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m         **self.gp_kwargs,\n\u001b[1;32m    270\u001b[0m     )\n\u001b[0;32m--> 271\u001b[0m else:\n\u001b[1;32m    272\u001b[0m     model = SingleTaskGP(\n\u001b[1;32m    273\u001b[0m         train_X=X,\n\u001b[1;32m    274\u001b[0m         train_Y=Y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    278\u001b[0m         **self.gp_kwargs,\n\u001b[1;32m    279\u001b[0m     )\n\u001b[1;32m    280\u001b[0m return model\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BayesianOptimizer' object has no attribute 'X_'"
     ]
    }
   ],
   "source": [
    "bo._fit_gp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "911ffdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_bo = BODummy(kernel=\"rbf\", sigma=600.0)\n",
    "gp_model = dummy_bo.fit_gp(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1f56bcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengthscales = gp_model.covar_module.lengthscale.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "07b03612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6216, 3.1009, 2.9917, 3.0620, 2.9310, 2.7654, 3.1144, 3.1266, 2.9056,\n",
       "         3.2067, 3.2410, 3.1313, 2.9617, 2.8898, 3.0868, 2.9062, 2.8429, 2.9631,\n",
       "         3.1662, 3.1969, 3.1129, 2.9449, 2.8465, 2.9153, 2.7852, 2.8693, 3.0290,\n",
       "         3.0473, 3.2011, 3.0324, 3.0352, 3.2102, 2.7638, 2.9594, 3.0514, 2.0055,\n",
       "         2.9962, 2.8593, 3.0111, 2.9058, 2.8175, 3.1221, 2.9532, 2.8024, 3.1777,\n",
       "         3.1293, 2.6101, 3.0613, 2.6592, 2.9229, 3.0549, 3.1112, 3.0200, 2.7899,\n",
       "         2.9407, 2.8691, 2.9038, 2.8370, 3.2235, 3.0284, 3.0935, 2.8904, 2.8661,\n",
       "         3.1060, 3.1457, 2.9983, 2.9538, 3.0739, 2.9039, 3.1143, 2.5759, 3.0153,\n",
       "         3.0839, 3.0536, 3.0007, 2.8201, 3.0567, 2.3274, 3.0893, 3.2183, 2.8318,\n",
       "         2.7368, 3.0397, 3.0314, 3.1944, 2.8421, 3.1432, 3.0316, 2.9595, 2.7896,\n",
       "         2.9240, 2.9274, 2.8796, 3.0798, 3.0508, 3.0058, 2.7088, 0.2645, 2.9860,\n",
       "         2.9072, 3.0529, 2.9217, 3.0948, 3.1142, 2.9293, 3.0725, 2.7937, 2.8648,\n",
       "         3.1465, 2.8247, 2.9276, 2.9825, 2.8274, 2.9017, 3.0117, 2.7519, 2.9659,\n",
       "         3.0778, 2.8039, 2.8619, 2.9563, 3.1767, 2.8291, 3.0090, 2.7639, 3.1143,\n",
       "         2.7942, 2.9639, 3.1573, 3.0122, 3.1777, 2.8325, 2.8418, 3.1945, 3.1791,\n",
       "         3.0129, 2.8577, 2.8540, 2.7117, 2.9728, 2.8271, 3.0119, 3.1595, 3.2109,\n",
       "         3.0247, 3.1579, 3.1195, 2.8504, 3.0517, 3.1932, 3.0615, 2.7789, 2.5694,\n",
       "         3.0520, 2.8815, 2.9745, 3.0613, 2.8395, 3.1622, 3.0235, 2.7424, 2.7565,\n",
       "         3.1295, 3.2130, 2.5035, 2.9770, 3.0642, 3.0791, 3.2230, 2.9719, 2.7577,\n",
       "         2.9880, 2.7547, 3.0580, 3.1344, 2.4683, 3.0197, 2.8054, 3.0165, 3.1281,\n",
       "         3.0296]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengthscales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "16e0adf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.fit import fit_gpytorch_mll\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "mll = ExactMarginalLogLikelihood(gp_model.likelihood, gp_model)\n",
    "mll_fitted = fit_gpytorch_mll(mll, max_attempts=10, pick_best_of_all_attempts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "20c5a2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931,\n",
       "         0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931,\n",
       "         0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931,\n",
       "         0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931,\n",
       "         0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931,\n",
       "         0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931,\n",
       "         0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931,\n",
       "         0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931,\n",
       "         0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931,\n",
       "         0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931,\n",
       "         0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931,\n",
       "         0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931,\n",
       "         0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931,\n",
       "         0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931,\n",
       "         0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931,\n",
       "         0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931,\n",
       "         0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931,\n",
       "         0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931,\n",
       "         0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931,\n",
       "         0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931,\n",
       "         0.6931]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_model.covar_module.base_kernel.lengthscale.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8074b232",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = gp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "be362096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Adam 050] MLL(pre-step train): -74.216908 | MLL(post-step train): -74.216898\n",
      "[Adam 100] MLL(pre-step train): -74.216278 | MLL(post-step train): -74.216267\n",
      "[Adam 150] MLL(pre-step train): -74.215826 | MLL(post-step train): -74.215818\n",
      "[Adam 200] MLL(pre-step train): -74.215462 | MLL(post-step train): -74.215455\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[125], line 177\u001b[0m\n\u001b[1;32m    173\u001b[0m outputscale_prior \u001b[38;5;241m=\u001b[39m LogNormalPrior(loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)  \u001b[38;5;66;03m# fairly wide\u001b[39;00m\n\u001b[1;32m    174\u001b[0m noise_prior \u001b[38;5;241m=\u001b[39m GammaPrior(\u001b[38;5;241m1.1\u001b[39m, \u001b[38;5;241m0.05\u001b[39m)  \u001b[38;5;66;03m# pushes noise away from 0 but small\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m mll \u001b[38;5;241m=\u001b[39m \u001b[43mfit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_lbfgs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m print_kernel_diagnostics(gp)\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# 3) Scan MLL over two coords (change idx_i, idx_j на интересующие размеры)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[125], line 70\u001b[0m, in \u001b[0;36mfit_model\u001b[0;34m(gp, use_lbfgs, maxiter, lr)\u001b[0m\n\u001b[1;32m     68\u001b[0m output \u001b[38;5;241m=\u001b[39m gp(Xtr)  \u001b[38;5;66;03m# <-- use cached train inputs\u001b[39;00m\n\u001b[1;32m     69\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39mmll(output, Ytr))  \u001b[38;5;66;03m# <-- use transformed targets\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m50\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;66;03m# Pre-step value already in `loss`\u001b[39;00m\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/torch/_tensor.py:647\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    639\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    640\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    645\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    646\u001b[0m     )\n\u001b[0;32m--> 647\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/torch/autograd/__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/torch/autograd/graph.py:829\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.transforms import Normalize, Standardize\n",
    "from gpytorch.kernels import MaternKernel, RBFKernel, ScaleKernel\n",
    "from gpytorch.mlls.exact_marginal_log_likelihood import ExactMarginalLogLikelihood\n",
    "from gpytorch.priors import GammaPrior, LogNormalPrior\n",
    "from gpytorch.settings import fast_pred_var\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "\n",
    "# ---------- Evaluate MLL at current params ----------\n",
    "@torch.no_grad()\n",
    "def current_mll_value(gp):\n",
    "    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "    gp.eval()\n",
    "    gp.likelihood.eval()\n",
    "    Xtr = gp.train_inputs[0]\n",
    "    Ytr = gp.train_targets  # <-- transformed targets\n",
    "    val = torch.sum(mll(gp(Xtr), Ytr))  # scalar\n",
    "    return float(val.item())\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def current_mll_value_trainpath(gp):\n",
    "    # Evaluate the training MLL using the TRAIN code path (no grads)\n",
    "    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "\n",
    "    Xtr = gp.train_inputs[0]\n",
    "    Ytr = gp.train_targets\n",
    "\n",
    "    # Remember current modes to restore later\n",
    "    was_model_train = gp.training\n",
    "    was_lik_train = gp.likelihood.training\n",
    "\n",
    "    try:\n",
    "        gp.train()\n",
    "        gp.likelihood.train()\n",
    "        with torch.no_grad(), fast_pred_var(False):  # ensure exact train path\n",
    "            val = torch.sum(mll(gp(Xtr), Ytr)).item()\n",
    "    finally:\n",
    "        # restore original modes\n",
    "        gp.train(was_model_train)\n",
    "        gp.likelihood.train(was_lik_train)\n",
    "\n",
    "    return float(val)\n",
    "\n",
    "\n",
    "# ---------- Fitting helper (you can swap optimizer) ----------\n",
    "def fit_model(gp, use_lbfgs=True, maxiter=1000, lr=0.1):\n",
    "    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "    gp.train()\n",
    "    gp.likelihood.train()\n",
    "    Xtr = gp.train_inputs[0]\n",
    "    Ytr = gp.train_targets  # <-- transformed\n",
    "\n",
    "    if use_lbfgs:\n",
    "        fit_gpytorch_mll(mll)  # uses gp.train_inputs / train_targets internally\n",
    "    else:\n",
    "        opt = torch.optim.Adam(gp.parameters(), lr=lr)\n",
    "        for i in range(maxiter):\n",
    "            opt.zero_grad()\n",
    "            output = gp(Xtr)  # <-- use cached train inputs\n",
    "            loss = torch.sum(-mll(output, Ytr))  # <-- use transformed targets\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            if (i + 1) % 50 == 0:\n",
    "                # Pre-step value already in `loss`\n",
    "                mll_pre = -loss.item()\n",
    "\n",
    "                mll_post_train = current_mll_value_trainpath(gp)\n",
    "\n",
    "                print(\n",
    "                    f\"[Adam {i+1:03d}] \"\n",
    "                    f\"MLL(pre-step train): {mll_pre:.6f} | \"\n",
    "                    f\"MLL(post-step train): {mll_post_train:.6f}\"\n",
    "                )\n",
    "\n",
    "    gp.eval()\n",
    "    gp.likelihood.eval()\n",
    "    return mll\n",
    "\n",
    "\n",
    "# ---------- Diagnostics ----------\n",
    "def print_kernel_diagnostics(gp):\n",
    "    cov = gp.covar_module\n",
    "    base = cov\n",
    "    ls = base.lengthscale.detach().view(-1)  # if ARD: length d\n",
    "    noise = gp.likelihood.noise.detach()\n",
    "    print(\"Kernel:\", type(base).__name__)\n",
    "    print(\n",
    "        \"Lengthscale shape:\",\n",
    "        tuple(base.lengthscale.shape),\n",
    "        \"| values:\",\n",
    "        ls.cpu().numpy(),\n",
    "    )\n",
    "    print(\"Noise:\", noise)\n",
    "    # Check that ARD really enabled\n",
    "    print(\"ARD enabled?:\", (base.ard_num_dims is not None))\n",
    "    # Check grads allowed\n",
    "    print(\"lengthscale requires_grad:\", base.raw_lengthscale.requires_grad)\n",
    "\n",
    "\n",
    "# ---------- 2D grid over two chosen lengthscales ----------\n",
    "@torch.no_grad()\n",
    "def mll_grid_over_two_ls(\n",
    "    gp,\n",
    "    X,\n",
    "    Y,\n",
    "    idx_i=0,\n",
    "    idx_j=1,\n",
    "    ls_min=1e-2,\n",
    "    ls_max=5.0,\n",
    "    num=60,\n",
    "    logspace=False,\n",
    "):\n",
    "    import copy\n",
    "\n",
    "    gp2 = copy.deepcopy(gp)\n",
    "    base = gp2.covar_module.base_kernel\n",
    "    assert base.ard_num_dims is not None, \"ARD must be enabled for 2D scan.\"\n",
    "\n",
    "    ls0 = base.lengthscale.detach().clone().view(-1)  # (d,)\n",
    "\n",
    "    if logspace:\n",
    "        lsi = torch.logspace(math.log10(ls_min), math.log10(ls_max), num, dtype=X.dtype)\n",
    "        lsj = torch.logspace(math.log10(ls_min), math.log10(ls_max), num, dtype=X.dtype)\n",
    "    else:\n",
    "        lsi = torch.linspace(ls_min, ls_max, num, dtype=X.dtype)\n",
    "        lsj = torch.linspace(ls_min, ls_max, num, dtype=X.dtype)\n",
    "\n",
    "    Z = torch.empty(num, num, dtype=X.dtype)\n",
    "    mll = ExactMarginalLogLikelihood(gp2.likelihood, gp2)\n",
    "    gp2.train()\n",
    "    gp2.likelihood.train()\n",
    "\n",
    "    Xtr = gp2.train_inputs[0]\n",
    "    Ytr = gp2.train_targets  # <-- transformed targets\n",
    "\n",
    "    for a, vi in enumerate(lsi):\n",
    "        for b, vj in enumerate(lsj):\n",
    "            new_ls = ls0.clone()\n",
    "            new_ls[idx_i] = vi\n",
    "            new_ls[idx_j] = vj\n",
    "            base.lengthscale.copy_(new_ls.reshape(1, -1))\n",
    "            val = torch.sum(mll(gp2(Xtr), Ytr))  # scalar\n",
    "\n",
    "            Z[a, b] = val\n",
    "\n",
    "    return lsi, lsj, Z\n",
    "\n",
    "\n",
    "def plot_mll_contour(lsi, lsj, Z, title=\"Exact MLL over two lengthscales\"):\n",
    "    LSI, LSJ = torch.meshgrid(lsi, lsj, indexing=\"ij\")\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    cs = plt.contourf(LSI.cpu().numpy(), LSJ.cpu().numpy(), Z.cpu().numpy(), levels=30)\n",
    "    plt.xlabel(\"lengthscale[i]\")\n",
    "    plt.ylabel(\"lengthscale[j]\")\n",
    "    plt.title(title)\n",
    "    plt.colorbar(cs, label=\"Exact MLL\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ---------- Experiments ----------\n",
    "# 1) Priors often help break symmetry / tie:\n",
    "lengthscale_prior = LogNormalPrior(loc=math.log(0.5), scale=0.5)  # median ~0.5\n",
    "outputscale_prior = LogNormalPrior(loc=0.0, scale=1.0)  # fairly wide\n",
    "noise_prior = GammaPrior(1.1, 0.05)  # pushes noise away from 0 but small\n",
    "\n",
    "\n",
    "mll = fit_model(gp, use_lbfgs=False)\n",
    "print_kernel_diagnostics(gp)\n",
    "\n",
    "# 3) Scan MLL over two coords (change idx_i, idx_j на интересующие размеры)\n",
    "idx_i, idx_j = 0, 1\n",
    "lsi, lsj, Z = mll_grid_over_two_ls(\n",
    "    gp,\n",
    "    X,\n",
    "    Y,\n",
    "    idx_i=idx_i,\n",
    "    idx_j=idx_j,\n",
    "    ls_min=snap.arrays[\"bounds\"][0][0],\n",
    "    ls_max=snap.arrays[\"bounds\"][0][1],\n",
    "    num=10,\n",
    "    logspace=False,\n",
    ")\n",
    "plot_mll_contour(lsi, lsj, Z, title=f\"Exact MLL over ls[{idx_i}] & ls[{idx_j}]\")\n",
    "\n",
    "# 4) Повтори с другими init/priors/optimizer, сравни карты и итоговые длины шкал."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d987fcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current MLL -0.6090053653412244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FixedNoiseGaussianLikelihood(\n",
       "  (noise_covar): FixedGaussianNoise()\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp.train()\n",
    "gp.likelihood.train()\n",
    "\n",
    "print(\"Current MLL\", current_mll_value_trainpath(gp))\n",
    "\n",
    "gp.eval()\n",
    "gp.likelihood.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fe2cf7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.54919338,  1.54919338])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snap.arrays[\"bounds\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79037485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6d6731b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import warnings\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from pathlib import Path as _Path\n",
    "from typing import Any, Callable, Dict, List, Optional, Sequence, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from botorch.acquisition import LogExpectedImprovement\n",
    "from botorch.acquisition.analytic import ExpectedImprovement, PosteriorMean\n",
    "from botorch.exceptions.warnings import NumericsWarning  # BoTorch EI numerics\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.transforms import Normalize, Standardize\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.utils.sampling import draw_sobol_samples\n",
    "from gpytorch.kernels import MaternKernel, RBFKernel, ScaleKernel\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from numpy.typing import ArrayLike\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm, qmc\n",
    "from gpytorch.priors import LogNormalPrior, UniformPrior\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BODummy:\n",
    "    dim: int = field(init=False, repr=False)\n",
    "    kernel: str = \"matern\"  # \"matern\" | \"rbf\"\n",
    "    kernel_isotropic: bool = False\n",
    "    use_input_normalize: bool = True\n",
    "    normalize_y: bool = True\n",
    "    sigma: Optional[Union[float, np.ndarray]] = None  # observation std\n",
    "\n",
    "    device: Union[str, torch.device] = \"cpu\"\n",
    "    dtype: torch.dtype = torch.double\n",
    "\n",
    "    gp_kwargs: Dict = field(default_factory=dict)\n",
    "\n",
    "    def _build_covar_module(self):\n",
    "        ard = None if self.kernel_isotropic else self.dim\n",
    "        mu = np.sqrt(2.0) + 0.5 * np.log(self.dim)\n",
    "        sigma = np.sqrt(3.0)\n",
    "\n",
    "        lengthscale_prior = LogNormalPrior(loc=mu, scale=sigma)\n",
    "        # lengthscale_prior = UniformPrior(a=1.0, b=10**4)\n",
    "        base = (\n",
    "            MaternKernel(nu=2.5, ard_num_dims=ard, lengthscale_prior=lengthscale_prior)\n",
    "            if self.kernel == \"matern\"\n",
    "            else RBFKernel(ard_num_dims=ard, lengthscale_prior=lengthscale_prior)\n",
    "        )\n",
    "        new_ls = bo_torch._as_t(\n",
    "            np.random.uniform(10.0, 10**3, self.dim).reshape(1, -1),\n",
    "            device=self.device,\n",
    "            dtype=self.dtype,\n",
    "        )\n",
    "        base.lengthscale = new_ls\n",
    "        return base\n",
    "\n",
    "    def _create_gp_model(self, X: torch.Tensor, Y: torch.Tensor):\n",
    "        self.dim = X.shape[1]\n",
    "        input_tf = Normalize(self.dim) if self.use_input_normalize else None\n",
    "        outcome_tf = Standardize(m=1) if self.normalize_y else None\n",
    "        covar_module = self._build_covar_module()\n",
    "\n",
    "        # Fixed or inferred noise via SingleTaskGP\n",
    "        if self.sigma is not None:\n",
    "            if np.isscalar(self.sigma):\n",
    "                yvar_np = np.full(\n",
    "                    (Y.shape[0], 1), float(self.sigma) ** 2, dtype=np.float64\n",
    "                )\n",
    "            else:\n",
    "                sig = np.asarray(self.sigma, dtype=np.float64).reshape(-1)\n",
    "                assert sig.size in (1, int(Y.shape[0]))\n",
    "                sig_np = (\n",
    "                    sig\n",
    "                    if sig.size > 1\n",
    "                    else np.full(int(Y.shape[0]), sig[0], dtype=np.float64)\n",
    "                )\n",
    "                yvar_np = (sig_np**2).reshape(-1, 1)\n",
    "            Yvar = bo_torch._as_t(yvar_np, self.dtype, self.device)\n",
    "            model = SingleTaskGP(\n",
    "                train_X=X,\n",
    "                train_Y=Y,\n",
    "                train_Yvar=Yvar,\n",
    "                input_transform=input_tf,\n",
    "                outcome_transform=outcome_tf,\n",
    "                covar_module=covar_module,\n",
    "                **self.gp_kwargs,\n",
    "            )\n",
    "        else:\n",
    "            model = SingleTaskGP(\n",
    "                train_X=X,\n",
    "                train_Y=Y,\n",
    "                input_transform=input_tf,\n",
    "                outcome_transform=outcome_tf,\n",
    "                covar_module=covar_module,\n",
    "                **self.gp_kwargs,\n",
    "            )\n",
    "        return model\n",
    "\n",
    "    def fit_gp(self, X: torch.Tensor, Y: torch.Tensor):\n",
    "        model = self._create_gp_model(X, Y)\n",
    "        mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "        model.train()\n",
    "        model.likelihood.train()\n",
    "        fit_gpytorch_mll(mll, max_attempts=2)\n",
    "        model.eval()\n",
    "        model.likelihood.eval()\n",
    "        self.gp_ = model.to(self.device, dtype=self.dtype)\n",
    "        return self.gp_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "fbb9a615",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_bo = BODummy(kernel=\"rbf\", sigma=600.0)\n",
    "gp_model = dummy_bo.fit_gp(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9879e83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "\n",
    "def sample_lengthscales_torch(\n",
    "    d: int,\n",
    "    n: int = 1,\n",
    "    mu: float = 0.0,\n",
    "    sigma: float = 1.0,\n",
    "    device=None,\n",
    "    dtype=torch.double,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Returns ARD lengthscales with shape:\n",
    "      - (1, 1, d) if n == 1\n",
    "      - (n, 1, 1, d) if n > 1  (for multi-restart inits)\n",
    "    \"\"\"\n",
    "    device = device or torch.device(\"cpu\")\n",
    "    dist = torch.distributions.LogNormal(\n",
    "        loc=torch.tensor(mu, dtype=dtype, device=device),\n",
    "        scale=torch.tensor(sigma, dtype=dtype, device=device),\n",
    "    )\n",
    "    if n == 1:\n",
    "        ls = dist.sample((d,)).view(1, 1, d)\n",
    "    else:\n",
    "        ls = dist.sample((n, d)).view(n, 1, 1, d)\n",
    "    return ls\n",
    "\n",
    "\n",
    "def sample_lengthscales_vanilla_bo(d: int, n: int = 1, device=None, dtype=torch.double):\n",
    "    mu = math.sqrt(2.0) + 0.5 * math.log(d)  # dimension-scaled\n",
    "    sigma = math.sqrt(3.0)\n",
    "    return sample_lengthscales_torch(\n",
    "        d=d, n=n, mu=mu, sigma=sigma, device=device, dtype=dtype\n",
    "    )\n",
    "\n",
    "\n",
    "def sample_lengthscales_uniform(\n",
    "    d: int,\n",
    "    n: int = 1,\n",
    "    low: float = 1.0,\n",
    "    high: float = 10.0**4,\n",
    "    device=None,\n",
    "    dtype=torch.double,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Uniform sampler on [low, high] (ARD):\n",
    "      - (1, 1, d) if n == 1\n",
    "      - (n, 1, 1, d) if n > 1\n",
    "    \"\"\"\n",
    "    device = device or torch.device(\"cpu\")\n",
    "    lo = torch.as_tensor(low, dtype=dtype, device=device)\n",
    "    hi = torch.as_tensor(high, dtype=dtype, device=device)\n",
    "    dist = torch.distributions.Uniform(lo, hi)\n",
    "    if n == 1:\n",
    "        ls = dist.sample((d,)).view(1, 1, d)\n",
    "    else:\n",
    "        ls = dist.sample((n, d)).view(n, 1, 1, d)\n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "f2128d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logMLL -56.188668978838066\n",
      "MLL 3.9588688717345105e-25\n",
      "MLL -38.01169362295134\n",
      "logMLL -38.01169362295134\n",
      "MLL 3.102638746439475e-17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FixedNoiseGaussianLikelihood(\n",
       "  (noise_covar): FixedGaussianNoise()\n",
       ")"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_model.train()\n",
    "gp_model.likelihood.train()\n",
    "\n",
    "gp_model.covar_module.lengthscale = sample_lengthscales_vanilla_bo(dummy_bo.dim)\n",
    "v1 = current_mll_value_trainpath(gp_model)\n",
    "print(\"logMLL\", v1)\n",
    "print(\"MLL\", np.exp(v1))\n",
    "\n",
    "mll = ExactMarginalLogLikelihood(gp_model.likelihood, gp_model)\n",
    "fit_gpytorch_mll(mll, max_attempts=1)\n",
    "\n",
    "gp_model.train()\n",
    "gp_model.likelihood.train()\n",
    "\n",
    "print(\"MLL\", current_mll_value_trainpath(gp_model))\n",
    "v2 = current_mll_value_trainpath(gp_model)\n",
    "print(\"logMLL\", v2)\n",
    "print(\"MLL\", np.exp(v2))\n",
    "\n",
    "gp_model.eval()\n",
    "gp_model.likelihood.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6021f022",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_model.covar_module.lengthscale = sample_lengthscales_uniform(dummy_bo.dim, low=1.0, high=10**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "7844acfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9417645335842487)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-0.06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "1caf8a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLL -37.4009880694787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FixedNoiseGaussianLikelihood(\n",
       "  (noise_covar): FixedGaussianNoise()\n",
       ")"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_model = bo.get_gp()\n",
    "gp_model.train()\n",
    "gp_model.likelihood.train()\n",
    "\n",
    "print(\"MLL\", current_mll_value_trainpath(gp_model))\n",
    "\n",
    "gp_model.eval()\n",
    "gp_model.likelihood.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "2620760d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8671932212880178\n",
      "1.8981576026555536\n",
      "1.893638591463241\n",
      "1.893178352166313\n",
      "1.8882569562660056\n",
      "1.8874082724407408\n",
      "1.8787061607752722\n",
      "1.8910989800326212\n",
      "1.900934101764856\n",
      "1.8969757945130679\n",
      "1.8771511469455575\n",
      "1.8773370133067966\n",
      "1.8974320841990657\n",
      "1.8946173922883245\n",
      "1.8851448459143278\n",
      "1.885327620813761\n",
      "1.883104715576832\n",
      "1.8984403829877814\n",
      "1.8881171019225582\n",
      "1.7960335620388184\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[311], line 174\u001b[0m\n\u001b[1;32m    169\u001b[0m gp_model\u001b[38;5;241m.\u001b[39mlikelihood\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# gp_model.covar_module.lengthscale = sample_lengthscales_vanilla_bo(\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m#     dummy_bo.dim, low=1.0, high=10**2\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# ---------- Example ----------\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mcma_then_fit_lengthscales_only\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgp_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43msigma0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaxfevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimize_outputscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# set True if you want to fit outputscale too\u001b[39;49;00m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mls_bounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_noise_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# or None to keep whatever the model currently has\u001b[39;49;00m\n\u001b[1;32m    182\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "Cell \u001b[0;32mIn[311], line 154\u001b[0m, in \u001b[0;36mcma_then_fit_lengthscales_only\u001b[0;34m(gp, sigma0, maxfevals, optimize_outputscale, ls_bounds, os_bounds, seed, fixed_noise_value)\u001b[0m\n\u001b[1;32m    150\u001b[0m set_from_vec_lengthscales_and_maybe_outputscale(\n\u001b[1;32m    151\u001b[0m     gp, xbest, optimize_outputscale\u001b[38;5;241m=\u001b[39moptimize_outputscale\n\u001b[1;32m    152\u001b[0m )\n\u001b[1;32m    153\u001b[0m mll \u001b[38;5;241m=\u001b[39m ExactMarginalLogLikelihood(gp\u001b[38;5;241m.\u001b[39mlikelihood, gp)\n\u001b[0;32m--> 154\u001b[0m \u001b[43mfit_gpytorch_mll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmll\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# LBFGS-B refinement (noise stays frozen)\u001b[39;00m\n\u001b[1;32m    155\u001b[0m gp\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    156\u001b[0m gp\u001b[38;5;241m.\u001b[39mlikelihood\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/botorch/fit.py:115\u001b[0m, in \u001b[0;36mfit_gpytorch_mll\u001b[0;34m(mll, closure, optimizer, closure_kwargs, optimizer_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# defer to per-method defaults\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m optimizer\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFitGPyTorchMLL\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmll\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmll\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlikelihood\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmll\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclosure_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/botorch/utils/dispatcher.py:95\u001b[0m, in \u001b[0;36mDispatcher.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(types\u001b[38;5;241m=\u001b[39mtypes)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MDNotImplementedError:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# Traverses registered methods in order, yields whenever a match is found\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     funcs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_iter(\u001b[38;5;241m*\u001b[39mtypes)\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/botorch/fit.py:215\u001b[0m, in \u001b[0;36m_fit_fallback\u001b[0;34m(mll, _, __, closure, optimizer, closure_kwargs, optimizer_kwargs, max_attempts, pick_best_of_all_attempts, warning_handler, caught_exception_types, **ignore)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m catch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m warning_list:\n\u001b[1;32m    214\u001b[0m     simplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malways\u001b[39m\u001b[38;5;124m\"\u001b[39m, category\u001b[38;5;241m=\u001b[39mOptimizationWarning)\n\u001b[0;32m--> 215\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;66;03m# Resolve warnings and determine whether or not to retry\u001b[39;00m\n\u001b[1;32m    218\u001b[0m success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/botorch/optim/fit.py:94\u001b[0m, in \u001b[0;36mfit_gpytorch_mll_scipy\u001b[0;34m(mll, parameters, bounds, closure, closure_kwargs, method, options, callback, timeout_sec)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     closure \u001b[38;5;241m=\u001b[39m partial(closure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mclosure_kwargs)\n\u001b[0;32m---> 94\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mscipy_minimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_sec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_sec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [OptimizationStatus\u001b[38;5;241m.\u001b[39mSUCCESS, OptimizationStatus\u001b[38;5;241m.\u001b[39mSTOPPED]:\n\u001b[1;32m    104\u001b[0m     warn(\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`scipy_minimize` terminated with status \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, displaying\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m original message from `scipy.optimize.minimize`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    107\u001b[0m         OptimizationWarning,\n\u001b[1;32m    108\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    109\u001b[0m     )\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/botorch/optim/core.py:115\u001b[0m, in \u001b[0;36mscipy_minimize\u001b[0;34m(closure, parameters, bounds, callback, x0, method, options, timeout_sec)\u001b[0m\n\u001b[1;32m    107\u001b[0m         result \u001b[38;5;241m=\u001b[39m OptimizationResult(\n\u001b[1;32m    108\u001b[0m             step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mnext\u001b[39m(call_counter),\n\u001b[1;32m    109\u001b[0m             fval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(wrapped_closure(x)[\u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m    110\u001b[0m             status\u001b[38;5;241m=\u001b[39mOptimizationStatus\u001b[38;5;241m.\u001b[39mRUNNING,\n\u001b[1;32m    111\u001b[0m             runtime\u001b[38;5;241m=\u001b[39mmonotonic() \u001b[38;5;241m-\u001b[39m start_time,\n\u001b[1;32m    112\u001b[0m         )\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m callback(parameters, result)  \u001b[38;5;66;03m# pyre-ignore [29]\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m raw \u001b[38;5;241m=\u001b[39m \u001b[43mminimize_with_timeout\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrapped_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrapped_closure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp_float64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds_np\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrapped_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_sec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_sec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# Post-processing and outcome handling\u001b[39;00m\n\u001b[1;32m    127\u001b[0m wrapped_closure\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m asarray(raw\u001b[38;5;241m.\u001b[39mx)  \u001b[38;5;66;03m# set parameter state to optimal values\u001b[39;00m\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/botorch/optim/utils/timeout.py:86\u001b[0m, in \u001b[0;36mminimize_with_timeout\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options, timeout_sec)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;66;03m# To prevent slowdowns after scipy 1.15.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;66;03m# See https://github.com/scipy/scipy/issues/22438.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m threadpool_limits(limits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, user_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblas\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 86\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m            \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhessp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhessp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrapped_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OptimizationTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    101\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimization timed out after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mruntime\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/scipy/optimize/_minimize.py:738\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    735\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    736\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 738\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    741\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    742\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py:441\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    433\u001b[0m _lbfgsb\u001b[38;5;241m.\u001b[39msetulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr, pgtol, wa,\n\u001b[1;32m    434\u001b[0m                iwa, task, lsave, isave, dsave, maxls, ln_task)\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 441\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    444\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:344\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x(x)\n\u001b[0;32m--> 344\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:295\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 295\u001b[0m         fx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m fx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_f:\n\u001b[1;32m    297\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:21\u001b[0m, in \u001b[0;36m_wrapper_fun.<locals>.wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     17\u001b[0m ncalls[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/scipy/optimize/_optimize.py:80\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     79\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/scipy/optimize/_optimize.py:74\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 74\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/botorch/optim/closures/core.py:83\u001b[0m, in \u001b[0;36mNdarrayOptimizationClosure.__call__\u001b[0;34m(self, state, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m state\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 83\u001b[0m     value_tensor, grad_tensors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     value \u001b[38;5;241m=\u001b[39m as_ndarray(values\u001b[38;5;241m=\u001b[39mvalue_tensor, dtype\u001b[38;5;241m=\u001b[39mnp_float64)\n\u001b[1;32m     85\u001b[0m     grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_gradient_ndarray()\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/botorch/optim/closures/core.py:46\u001b[0m, in \u001b[0;36mForwardBackwardClosure.__call__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m zero_grad_ctx(parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters):\n\u001b[1;32m     45\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m---> 46\u001b[0m     \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(param\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value, grads\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/torch/_tensor.py:647\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    639\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    640\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    645\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    646\u001b[0m     )\n\u001b[0;32m--> 647\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/torch/autograd/__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/torch/autograd/graph.py:829\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %% CMA-ES -> fit_gpytorch_mll, optimizing ONLY lengthscales (and optional outputscale)\n",
    "import math\n",
    "\n",
    "import cma\n",
    "import numpy as np\n",
    "import torch\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from cma.boundary_handler import BoundTransform\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from gpytorch.settings import fast_pred_var\n",
    "\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "\n",
    "# ---------- Utilities ----------\n",
    "def _has_scalekernel(gp) -> bool:\n",
    "    from gpytorch.kernels import ScaleKernel\n",
    "\n",
    "    return isinstance(gp.covar_module, ScaleKernel)\n",
    "\n",
    "\n",
    "def _base_kernel(gp):\n",
    "    return gp.covar_module.base_kernel if _has_scalekernel(gp) else gp.covar_module\n",
    "\n",
    "\n",
    "def trainpath_mll(gp) -> float:\n",
    "    \"\"\"Exact training-path MLL on cached train tensors (consistent with fitting).\"\"\"\n",
    "    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "    Xtr = gp.train_inputs[0]\n",
    "    Ytr = gp.train_targets\n",
    "    with torch.no_grad(), fast_pred_var(False):\n",
    "        return float(torch.sum(mll(gp(Xtr), Ytr)).item())\n",
    "\n",
    "\n",
    "# ---------- Pack / set hypers (NO NOISE in the vector) ----------\n",
    "def pack_lengthscales_and_maybe_outputscale(\n",
    "    gp, optimize_outputscale: bool = False\n",
    ") -> np.ndarray:\n",
    "    base = _base_kernel(gp)\n",
    "    ls = base.lengthscale.detach().reshape(-1)  # (d_ard,)\n",
    "    parts = [torch.log(ls)]\n",
    "    if optimize_outputscale and _has_scalekernel(gp):\n",
    "        os = gp.covar_module.outputscale.detach().reshape(1)  # (1,)\n",
    "        parts.append(torch.log(os))\n",
    "    z = torch.cat(parts).cpu().numpy()\n",
    "    return z\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def set_from_vec_lengthscales_and_maybe_outputscale(\n",
    "    gp, z: np.ndarray, optimize_outputscale: bool = False\n",
    "):\n",
    "    t = torch.as_tensor(z, dtype=torch.double, device=next(gp.parameters()).device)\n",
    "    base = _base_kernel(gp)\n",
    "    d = base.lengthscale.numel()\n",
    "    idx = 0\n",
    "    ls = torch.exp(t[idx : idx + d])\n",
    "    idx += d\n",
    "    base.lengthscale = ls.view(1, 1, d)  # ARD-safe\n",
    "    if optimize_outputscale and _has_scalekernel(gp):\n",
    "        os = torch.exp(t[idx])\n",
    "        gp.covar_module.outputscale = os.item()\n",
    "\n",
    "\n",
    "def build_log_bounds_for_lengthscales_and_maybe_outputscale(\n",
    "    gp, optimize_outputscale: bool, ls_bounds=(1e-3, 1e4), os_bounds=(1e-3, 1e4)\n",
    "):\n",
    "    base = _base_kernel(gp)\n",
    "    d = base.lengthscale.numel()\n",
    "    lo = [math.log(ls_bounds[0])] * d\n",
    "    hi = [math.log(ls_bounds[1])] * d\n",
    "    if optimize_outputscale and _has_scalekernel(gp):\n",
    "        lo.append(math.log(os_bounds[0]))\n",
    "        hi.append(math.log(os_bounds[1]))\n",
    "    return np.array(lo, float), np.array(hi, float)\n",
    "\n",
    "\n",
    "# ---------- CMA objective (minimize -MLL) ----------\n",
    "def make_cma_objective_lengthscales_only(gp, optimize_outputscale=False, verbose=False):\n",
    "    def f(z: np.ndarray) -> float:\n",
    "        set_from_vec_lengthscales_and_maybe_outputscale(\n",
    "            gp, z, optimize_outputscale=optimize_outputscale\n",
    "        )\n",
    "        val = -trainpath_mll(gp)\n",
    "        print(val)\n",
    "        if not np.isfinite(val):\n",
    "            return 1e100\n",
    "        if verbose:\n",
    "            print(f\"objective = {val:.6f}\")\n",
    "        return float(val)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "# ---------- Main routine ----------\n",
    "def cma_then_fit_lengthscales_only(\n",
    "    gp,\n",
    "    sigma0: float = 0.5,  # initial step on log-scale\n",
    "    maxfevals: int = 2000,\n",
    "    optimize_outputscale: bool = False,\n",
    "    ls_bounds=(1e-3, 1e4),\n",
    "    os_bounds=(1e-3, 1e4),\n",
    "    seed: int | None = None,\n",
    "    fixed_noise_value: float | None = None,  # set a specific noise, or leave as-is\n",
    "):\n",
    "    \"\"\"\n",
    "    1) Freeze noise so it's not optimized.\n",
    "    2) Run CMA-ES on (log lengthscales [+ optional log outputscale]).\n",
    "    3) Refine with fit_gpytorch_mll (noise remains frozen).\n",
    "    \"\"\"\n",
    "    # --- Freeze noise ---\n",
    "    # Optionally set a fixed value (kept constant during optimization).\n",
    "\n",
    "    if fixed_noise_value is not None:\n",
    "        gp.likelihood.noise = float(fixed_noise_value)\n",
    "    gp.likelihood.noise_covar.noise.requires_grad_(False)  # do not fit noise\n",
    "\n",
    "    # --- CMA setup (log-space) ---\n",
    "    x0 = pack_lengthscales_and_maybe_outputscale(\n",
    "        gp, optimize_outputscale=optimize_outputscale\n",
    "    )\n",
    "    lo, hi = build_log_bounds_for_lengthscales_and_maybe_outputscale(\n",
    "        gp,\n",
    "        optimize_outputscale=optimize_outputscale,\n",
    "        ls_bounds=ls_bounds,\n",
    "        os_bounds=os_bounds,\n",
    "    )\n",
    "    tolx = 1e-10\n",
    "    tolfun = 1e-1\n",
    "    tolfunhist = 1e-1\n",
    "    opts = {\n",
    "        \"bounds\": [lo, hi],  # elementwise bounds in log-space\n",
    "        \"BoundaryHandler\": BoundTransform,\n",
    "        \"seed\": seed,\n",
    "        \"maxfevals\": maxfevals,\n",
    "        \"verb_log\": 0,\n",
    "        \"verbose\": -9,\n",
    "        \"tolx\": tolx,\n",
    "        \"tolfun\": tolfun,\n",
    "        \"tolfunhist\": tolfunhist,\n",
    "    }\n",
    "    f = make_cma_objective_lengthscales_only(\n",
    "        gp, optimize_outputscale=optimize_outputscale, verbose=False\n",
    "    )\n",
    "\n",
    "    # --- Run CMA ---\n",
    "    xbest, fbest, *_ = cma.fmin(f, x0, sigma0, options=opts)\n",
    "\n",
    "    # Apply best and refine with gradient fit\n",
    "    set_from_vec_lengthscales_and_maybe_outputscale(\n",
    "        gp, xbest, optimize_outputscale=optimize_outputscale\n",
    "    )\n",
    "    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "    fit_gpytorch_mll(mll)  # LBFGS-B refinement (noise stays frozen)\n",
    "    gp.train()\n",
    "    gp.likelihood.train()\n",
    "    ans = trainpath_mll(gp)\n",
    "    gp.eval()\n",
    "    gp.likelihood.eval()\n",
    "\n",
    "    return {\n",
    "        \"xbest\": xbest,\n",
    "        \"fbest\": fbest,  # CMA objective value (-MLL) at best\n",
    "        \"mll_after_refine\": ans,  # train-path MLL after refinement\n",
    "    }\n",
    "\n",
    "\n",
    "gp_model.train()\n",
    "gp_model.likelihood.train()\n",
    "# gp_model.covar_module.lengthscale = sample_lengthscales_vanilla_bo(\n",
    "#     dummy_bo.dim, low=1.0, high=10**2\n",
    "# )\n",
    "# ---------- Example ----------\n",
    "result = cma_then_fit_lengthscales_only(\n",
    "    gp_model,\n",
    "    sigma0=2.0,\n",
    "    maxfevals=1000,\n",
    "    optimize_outputscale=False,  # set True if you want to fit outputscale too\n",
    "    ls_bounds=(1e-3, 1e3),\n",
    "    seed=1,\n",
    "    fixed_noise_value=None,  # or None to keep whatever the model currently has\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eba6210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "2612d491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9644,  1.1336,  1.0963,  1.1198,  1.0760,  1.0178,  1.1373,  1.1405,\n",
       "          1.0676,  1.1665,  1.1767,  1.1420,  1.0865,  1.0625,  1.1278,  1.0689,\n",
       "          1.0444,  1.0875,  1.1532,  1.1631,  1.1366,  1.0805,  1.0473,  1.0708,\n",
       "          1.0259,  1.0549,  1.1092,  1.1149,  1.1647,  1.1100,  1.1112,  1.1670,\n",
       "          1.0183,  1.0857,  1.1159,  0.6921,  1.0982,  1.0511,  1.1034,  1.0675,\n",
       "          1.0369,  1.1392,  1.0842,  1.0324,  1.1572,  1.1417,  0.9597,  1.1197,\n",
       "          0.9787,  1.0729,  1.1182,  1.1356,  1.1053,  1.0271,  1.0791,  1.0545,\n",
       "          1.0665,  1.0435,  1.1711,  1.1086,  1.1293,  1.0616,  1.0534,  1.1336,\n",
       "          1.1465,  1.0989,  1.0834,  1.1245,  1.0669,  1.1367,  0.9477,  1.1044,\n",
       "          1.1270,  1.1175,  1.0996,  1.0382,  1.1181,  0.8453,  1.1288,  1.1703,\n",
       "          1.0422,  1.0065,  1.1122,  1.1094,  1.1630,  1.0453,  1.1463,  1.1099,\n",
       "          1.0857,  1.0261,  1.0733,  1.0751,  1.0580,  1.1256,  1.1154,  1.1011,\n",
       "          0.9973, -1.3295,  1.0951,  1.0683,  1.1168,  1.0728,  1.1308,  1.1368,\n",
       "          1.0755,  1.1228,  1.0278,  1.0529,  1.1471,  1.0390,  1.0747,  1.0945,\n",
       "          1.0400,  1.0669,  1.1029,  1.0127,  1.0869,  1.1246,  1.0315,  1.0521,\n",
       "          1.0843,  1.1568,  1.0404,  1.1022,  1.0175,  1.1368,  1.0279,  1.0871,\n",
       "          1.1507,  1.1030,  1.1569,  1.0417,  1.0456,  1.1620,  1.1576,  1.1034,\n",
       "          1.0511,  1.0488,  0.9969,  1.0896,  1.0405,  1.1031,  1.1514,  1.1673,\n",
       "          1.1075,  1.1506,  1.1385,  1.0480,  1.1166,  1.1616,  1.1195,  1.0230,\n",
       "          0.9453,  1.1166,  1.0584,  1.0904,  1.1199,  1.0439,  1.1519,  1.1075,\n",
       "          1.0095,  1.0148,  1.1418,  1.1680,  0.9189,  1.0913,  9.5811,  1.1251,\n",
       "          1.1718,  1.0902,  1.0140,  1.0958,  1.0139,  1.1185,  1.1426,  0.9055,\n",
       "          1.1067,  1.0324,  1.1044,  1.1404,  1.1094]])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(_base_kernel(gp_model).lengthscale.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "987eb569",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ExactGP' from 'botorch.models' (/data/antonovk/venv-cvrp/lib/python3.10/site-packages/botorch/models/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[113], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 6\u001b[0m \u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbo_torch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m snap \u001b[38;5;241m=\u001b[39m bo_torch\u001b[38;5;241m.\u001b[39mBayesianOptimizer\u001b[38;5;241m.\u001b[39mload_snapshot(\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../outputs/2025-09-15-21h53m45s/per-instance-param-control/X-n101-k25/bo-final\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m arrays_file \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\n\u001b[1;32m     13\u001b[0m     Path(\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../outputs/2025-09-15-20h59m23s/per-instance-param-control/X-n101-k25/rs-final/arrays.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m     )\n\u001b[1;32m     16\u001b[0m )\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/importlib/__init__.py:169\u001b[0m, in \u001b[0;36mreload\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspec not found for the module \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m--> 169\u001b[0m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The module may have replaced itself in sys.modules!\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules[name]\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:619\u001b[0m, in \u001b[0;36m_exec\u001b[0;34m(spec, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/data/antonovk/FewShotCVRP/FewShotCVRP/bo/bo_torch.py:16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbotorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwarnings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NumericsWarning  \u001b[38;5;66;03m# BoTorch EI numerics\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbotorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fit_gpytorch_mll\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbotorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExactGP, SingleTaskGP\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbotorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Normalize, Standardize\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbotorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m optimize_acqf\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ExactGP' from 'botorch.models' (/data/antonovk/venv-cvrp/lib/python3.10/site-packages/botorch/models/__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import FewShotCVRP.bo.bo_torch as bo_torch\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "reload(bo_torch)\n",
    "\n",
    "snap = bo_torch.BayesianOptimizer.load_snapshot(\n",
    "    \"../outputs/2025-09-15-21h53m45s/per-instance-param-control/X-n101-k25/bo-final\"\n",
    ")\n",
    "\n",
    "arrays_file = np.load(\n",
    "    Path(\n",
    "        \"../outputs/2025-09-15-20h59m23s/per-instance-param-control/X-n101-k25/rs-final/arrays.npz\"\n",
    "    )\n",
    ")\n",
    "arrays = {k: arrays_file[k] for k in arrays_file.files}\n",
    "\n",
    "X = bo_torch._as_t(arrays[\"X_\"], dtype=torch.double, device=\"cpu\")\n",
    "Y = bo_torch._as_t(arrays[\"y_\"].reshape(-1, 1), dtype=torch.double, device=\"cpu\")\n",
    "\n",
    "\n",
    "bo_cfg = snap.experiment_config[\"bo\"]\n",
    "bo = bo_torch.BayesianOptimizer(\n",
    "    None,\n",
    "    f_batch=None,\n",
    "    bounds=snap.arrays[\"bounds\"],\n",
    "    n_init=int(bo_cfg[\"n_init\"]),\n",
    "    n_iter=int(bo_cfg[\"n_iter\"]),\n",
    "    sigma=float(bo_cfg[\"sigma\"]),\n",
    "    kernel=str(bo_cfg[\"kernel\"]),\n",
    "    kernel_isotropic=bool(bo_cfg[\"kernel_isotropic\"]),\n",
    "    use_input_normalize=bool(bo_cfg[\"use_input_normalize\"]),\n",
    "    normalize_y=bool(bo_cfg[\"normalize_y\"]),\n",
    "    doe_method=str(bo_cfg[\"doe_method\"]),\n",
    "    n_restarts_acq_opt=int(bo_cfg[\"n_restarts_acq_opt\"]),\n",
    "    suggestions_per_step=int(bo_cfg[\"suggestions_per_step\"]),\n",
    "    diversity_frac=float(bo_cfg[\"diversity_frac\"]),\n",
    "    random_state=snap.experiment_config[\"random_seed\"],\n",
    ")\n",
    "bo.X_ = X\n",
    "bo.y_ = Y\n",
    "\n",
    "gp_model = bo._create_gp_model(\n",
    "    X,\n",
    "    Y,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3e81d573",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m reload(gp_fitting)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# ----------------------------- usage ---------------------------------\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# gp is your model (e.g., SingleTaskGP) already constructed with data.\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m gp, info \u001b[38;5;241m=\u001b[39m \u001b[43mgp_fitting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_mll\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgp_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaxfevals_cma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_timeout_sec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_lengthscales_with_vanilla_bo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(info)\n",
      "File \u001b[0;32m/data/antonovk/FewShotCVRP/FewShotCVRP/bo/gp_fitting.py:672\u001b[0m, in \u001b[0;36moptimize_mll\u001b[0;34m(gp, sigma0, maxfevals_cma, maxfevals_grad, grad_timeout_sec, tolx_cma, tolfun_cma, tolfunhist_cma, tolfun_grad, tolgrad_grad, ls_bounds, os_bounds, noise_bounds, mean_bounds, period_bounds, seed, do_refine_with_fit, init_lengthscales_with_vanilla_bo, verbose)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sigma0 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    670\u001b[0m     sigma0 \u001b[38;5;241m=\u001b[39m _sigma0_from_bounds(lo, hi, rule\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquarter\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[43m_objective_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    673\u001b[0m opts \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbounds\u001b[39m\u001b[38;5;124m\"\u001b[39m: [lo\u001b[38;5;241m.\u001b[39mtolist(), hi\u001b[38;5;241m.\u001b[39mtolist()],  \u001b[38;5;66;03m# bounds in z-space\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    681\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtolfunhist\u001b[39m\u001b[38;5;124m\"\u001b[39m: tolfunhist_cma,\n\u001b[1;32m    682\u001b[0m }\n\u001b[1;32m    683\u001b[0m xbest, fbest, \u001b[38;5;241m*\u001b[39m_ \u001b[38;5;241m=\u001b[39m cma\u001b[38;5;241m.\u001b[39mfmin(\n\u001b[1;32m    684\u001b[0m     f, z0, sigma0, eval_initial_x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, options\u001b[38;5;241m=\u001b[39mopts\n\u001b[1;32m    685\u001b[0m )  \u001b[38;5;66;03m# runs CMA-ES\u001b[39;00m\n",
      "File \u001b[0;32m/data/antonovk/FewShotCVRP/FewShotCVRP/bo/gp_fitting.py:517\u001b[0m, in \u001b[0;36m_objective_factory\u001b[0;34m(gp, items, verbose)\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCMA-ES MLL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m-\u001b[39mval\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(val)\n\u001b[0;32m--> 517\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/torch/__init__.py:2628\u001b[0m, in \u001b[0;36mcompile\u001b[0;34m(model, fullgraph, dynamic, backend, mode, options, disable)\u001b[0m\n\u001b[1;32m   2625\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2626\u001b[0m     backend \u001b[38;5;241m=\u001b[39m _TorchCompileWrapper(backend, mode, options, dynamic)\n\u001b[0;32m-> 2628\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2629\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2630\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnopython\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfullgraph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2631\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2633\u001b[0m \u001b[43m    \u001b[49m\u001b[43mguard_filter_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mguard_filter_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2634\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m(model)\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:1052\u001b[0m, in \u001b[0;36moptimize\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnopython\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ca_kwargs_override[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfullgraph\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m optimize(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1052\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrebuild_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:1135\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(rebuild_ctx, backend, nopython, guard_export_fn, guard_fail_fn, guard_filter_fn, disable, dynamic, package)\u001b[0m\n\u001b[1;32m   1124\u001b[0m backend_ctx_ctor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(backend, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackend_ctx_ctor\u001b[39m\u001b[38;5;124m\"\u001b[39m, null_context)\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# The backend function is stashed in the callable returned by\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# _optimize_catch_errors in the field _torchdynamo_orig_callable. This can\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;66;03m# be used by eval_frame.c to insert a guard on the backend.\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _optimize_catch_errors(\n\u001b[1;32m   1130\u001b[0m     convert_frame\u001b[38;5;241m.\u001b[39mconvert_frame(backend, hooks\u001b[38;5;241m=\u001b[39mhooks, package\u001b[38;5;241m=\u001b[39mpackage),\n\u001b[1;32m   1131\u001b[0m     hooks,\n\u001b[1;32m   1132\u001b[0m     backend_ctx_ctor,\n\u001b[1;32m   1133\u001b[0m     dynamic\u001b[38;5;241m=\u001b[39mdynamic,\n\u001b[1;32m   1134\u001b[0m     compiler_config\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m-> 1135\u001b[0m         \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_compiler_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(backend, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_compiler_config\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m     ),\n\u001b[1;32m   1139\u001b[0m     rebuild_ctx\u001b[38;5;241m=\u001b[39mrebuild_ctx,\n\u001b[1;32m   1140\u001b[0m     package\u001b[38;5;241m=\u001b[39mpackage,\n\u001b[1;32m   1141\u001b[0m )\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/torch/__init__.py:2383\u001b[0m, in \u001b[0;36m_TorchCompileInductorWrapper.get_compiler_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_compiler_config\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 2383\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inductor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompile_fx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_patched_config_dict\n\u001b[1;32m   2385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_patched_config_dict(config_patches\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig)\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping_extensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Never, override, ParamSpec, Protocol, TypedDict, Unpack\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01munittest\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mock\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inductor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masync_compile\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401 required to warm up AsyncCompile pools\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpytree\u001b[39;00m\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/torch/_inductor/async_compile.py:534\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     \u001b[43mAsyncCompile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarm_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;66;03m# On exit give the workers a chance to clean themselves up. Without this the\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;66;03m# resource_tracker can complain about leaked semaphores coming from the\u001b[39;00m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;66;03m# ProcessPoolExecutor:\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;66;03m#   UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;66;03m#   to clean up at shutdown\u001b[39;00m\n\u001b[1;32m    541\u001b[0m atexit\u001b[38;5;241m.\u001b[39mregister(shutdown_compile_workers)\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/torch/_inductor/async_compile.py:279\u001b[0m, in \u001b[0;36mAsyncCompile.warm_pool\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    277\u001b[0m _compile_start()\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# Pool is initialized on first access\u001b[39;00m\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m _compile_end()\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/torch/_inductor/async_compile.py:250\u001b[0m, in \u001b[0;36mAsyncCompile.process_pool\u001b[0;34m()\u001b[0m\n\u001b[1;32m    247\u001b[0m pool: AnyPool\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mworker_start_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubprocess\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;66;03m# Wrapper around ProcessPoolExecutor forks in a new process we control\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m     pool \u001b[38;5;241m=\u001b[39m \u001b[43mSubprocPool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_compile_threads\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mworker_start_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;66;03m# Avoid creating pools in the spawned subprocs themselves:\u001b[39;00m\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py:124\u001b[0m, in \u001b[0;36mSubprocPool.__init__\u001b[0;34m(self, nprocs, pickler, kind)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_pipe \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfdopen(write_fd, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_pipe \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfdopen(read_fd, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 124\u001b[0m torch_key_str \u001b[38;5;241m=\u001b[39m base64\u001b[38;5;241m.\u001b[39mb64encode(\u001b[43mtorch_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    126\u001b[0m cmd \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    127\u001b[0m     sys\u001b[38;5;241m.\u001b[39mexecutable,\n\u001b[1;32m    128\u001b[0m     entry,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--torch-key=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch_key_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    136\u001b[0m ]\n\u001b[1;32m    137\u001b[0m local \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/torch/_inductor/codecache.py:718\u001b[0m, in \u001b[0;36mtorch_key_cache.<locals>.wrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbytes\u001b[39m:\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_cache) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 718\u001b[0m         _cache\u001b[38;5;241m.\u001b[39mappend(\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cache[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/torch/_inductor/codecache.py:760\u001b[0m, in \u001b[0;36mtorch_key\u001b[0;34m()\u001b[0m\n\u001b[1;32m    757\u001b[0m                     hasher\u001b[38;5;241m.\u001b[39mupdate(f\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m    758\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m hasher\u001b[38;5;241m.\u001b[39mdigest()\n\u001b[0;32m--> 760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_code_hash\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_TORCH_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlibfb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parutil\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m parutil\u001b[38;5;241m.\u001b[39mget_file_contents(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch/src_hash.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mrstrip()\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/torch/_inductor/codecache.py:753\u001b[0m, in \u001b[0;36mtorch_key.<locals>.get_code_hash\u001b[0;34m(root)\u001b[0m\n\u001b[1;32m    751\u001b[0m hasher \u001b[38;5;241m=\u001b[39m hashlib\u001b[38;5;241m.\u001b[39msha256()\n\u001b[1;32m    752\u001b[0m hasher\u001b[38;5;241m.\u001b[39mupdate(torch\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m--> 753\u001b[0m \u001b[43mbuild_code_hash\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m extra_files:\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(path):\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/torch/_inductor/codecache.py:705\u001b[0m, in \u001b[0;36mbuild_code_hash\u001b[0;34m(roots, prefix, hasher)\u001b[0m\n\u001b[1;32m    702\u001b[0m     hasher\u001b[38;5;241m.\u001b[39mupdate(f\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mispkg:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;66;03m# need to also hash submodules\u001b[39;00m\n\u001b[0;32m--> 705\u001b[0m     \u001b[43mbuild_code_hash\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmodule_search_locations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/torch/_inductor/codecache.py:702\u001b[0m, in \u001b[0;36mbuild_code_hash\u001b[0;34m(roots, prefix, hasher)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    701\u001b[0m     hasher\u001b[38;5;241m.\u001b[39mupdate(spec\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m--> 702\u001b[0m     hasher\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mispkg:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;66;03m# need to also hash submodules\u001b[39;00m\n\u001b[1;32m    705\u001b[0m     build_code_hash(spec\u001b[38;5;241m.\u001b[39msubmodule_search_locations, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, hasher)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import FewShotCVRP.bo.gp_fitting as gp_fitting\n",
    "\n",
    "reload(gp_fitting)\n",
    "\n",
    "# ----------------------------- usage ---------------------------------\n",
    "# gp is your model (e.g., SingleTaskGP) already constructed with data.\n",
    "gp, info = gp_fitting.optimize_mll(\n",
    "    gp_model,\n",
    "    seed=42,\n",
    "    maxfevals_cma=100,\n",
    "    grad_timeout_sec=60.0,\n",
    "    verbose=True,\n",
    "    init_lengthscales_with_vanilla_bo=True,\n",
    ")\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0ced19cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a real number, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m3\u001b[39m],[\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m]])\n\u001b[1;32m      2\u001b[0m X[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "X = np.array([[12,3],[4,5]])\n",
    "X[:2]\n",
    "int(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcd6878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06633c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FixedNoiseGaussianLikelihood(\n",
       "  (noise_covar): FixedGaussianNoise()\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "gp.train()\n",
    "gp.likelihood.train()\n",
    "# LBFGS-B refinement\n",
    "fit_gpytorch_mll(\n",
    "    mll,\n",
    "    optimizer_kwargs={\n",
    "        \"method\": \"L-BFGS-B\",\n",
    "        \"options\": {  # forwarded to scipy.optimize.minimize\n",
    "            # \"maxiter\": 50,  # cap iterations\n",
    "            \"maxfun\": 2000,  # cap f-evals (supported by L-BFGS-B)\n",
    "            # \"ftol\": 1e-3,\n",
    "            # \"gtol\": 1e-5,  # stopping tolerances\n",
    "        },\n",
    "        \"timeout_sec\": 30.0,  # hard wall-time budget set to 30 secs\n",
    "    },\n",
    "    max_attempts=10,  # BoTorch retries up to 5 times by default\n",
    ")\n",
    "gp.eval()\n",
    "gp.likelihood.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8e2ad8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.057805052153674,\n",
       " array([ 1.04909432e-03, -1.45044627e-05, -2.20245610e-06, -1.33779500e-06,\n",
       "        -1.68730538e-05,  1.11291131e-03,  1.26968483e-03,  5.99117790e-04,\n",
       "        -4.56110673e-06, -3.77858252e-06,  9.25034850e-04,  9.30905546e-04,\n",
       "        -5.89631083e-07,  5.91114394e-04,  1.13478267e-03,  8.84923218e-04,\n",
       "        -2.17647239e-05, -1.43710516e-05, -1.89481731e-05,  5.24100912e-04,\n",
       "         7.58198659e-04,  2.57590039e-04, -1.84512035e-06, -2.20050687e-05,\n",
       "         4.08201497e-04,  1.16820069e-03, -1.92895004e-07,  6.99301593e-04,\n",
       "        -3.03272675e-07,  5.36094779e-04,  7.36124341e-04, -8.43050322e-06,\n",
       "        -3.28652151e-07,  6.06623627e-05, -3.13014963e-06, -1.54327825e-07,\n",
       "         6.80418581e-04, -2.19668388e-05, -2.46688307e-06, -8.53470553e-06,\n",
       "         1.21808781e-03,  1.29620004e-03, -6.38806795e-07,  2.78897380e-04,\n",
       "        -2.15427877e-05,  9.98192550e-04, -1.39246333e-07,  1.12902237e-03,\n",
       "        -1.84729739e-05,  8.19710029e-04, -1.96428468e-06, -1.53807766e-06,\n",
       "        -1.21385191e-06, -5.18619485e-06,  1.19255322e-03,  6.09344700e-05,\n",
       "         2.63360431e-04,  4.83720513e-05, -1.42884831e-05, -3.12479029e-06,\n",
       "        -1.40637497e-06,  1.69941600e-04,  9.92423415e-04,  3.07493336e-04,\n",
       "        -1.21161214e-05, -3.66260928e-06,  3.84931333e-04, -1.51668974e-05,\n",
       "        -2.17971452e-05, -2.21024131e-05,  3.41933854e-04,  2.95564335e-04,\n",
       "        -1.28720853e-06,  1.10911024e-04,  4.19079695e-04,  5.06938840e-04,\n",
       "         2.19119946e-04,  1.05620426e-05, -7.43435949e-07,  3.73892740e-04,\n",
       "         4.23705919e-04, -7.35398420e-06, -2.20432696e-05, -2.19952166e-05,\n",
       "        -1.87387126e-05,  1.27827344e-03, -2.21569501e-05,  1.28298961e-04,\n",
       "        -3.21665491e-06,  5.35751694e-04, -2.85609509e-06, -1.66095847e-05,\n",
       "         8.32990645e-04,  4.21200495e-04,  1.05275742e-03,  1.00204041e-04,\n",
       "         3.50613442e-04, -1.96351280e-05, -8.66682785e-06, -2.12598181e-05,\n",
       "         2.40570274e-04, -6.35844619e-07,  4.99727931e-04, -2.17180572e-05,\n",
       "         1.26942577e-03,  9.98961434e-04, -1.97407149e-05, -1.34001551e-05,\n",
       "        -1.97223725e-05,  7.56073127e-04, -1.93645113e-05,  3.71332158e-04,\n",
       "         1.22061689e-04,  6.95192228e-05, -1.06025335e-06, -2.54133394e-06,\n",
       "         1.00491657e-03,  7.37213837e-04,  6.11788357e-04, -1.75826545e-05,\n",
       "         5.74408819e-04,  1.14870235e-05,  1.00727271e-03, -2.04373330e-05,\n",
       "        -2.05115574e-05, -2.87209900e-07, -3.04530058e-07, -2.15078173e-05,\n",
       "         2.53867436e-04, -3.93723350e-07, -1.45019976e-07,  1.64008897e-05,\n",
       "         3.03003177e-04, -1.54386359e-06, -1.88144619e-05,  1.36894727e-04,\n",
       "         1.27946235e-04, -4.47540206e-06, -7.88843584e-07, -1.22261659e-05,\n",
       "        -1.65656700e-07, -1.04012426e-05,  9.95382732e-04,  6.48283651e-04,\n",
       "        -9.82990440e-06,  5.43437933e-04, -1.25764316e-06, -2.03159616e-06,\n",
       "        -2.17943911e-05,  5.66380990e-05, -1.84700229e-05,  4.92922172e-04,\n",
       "         1.09209853e-03, -3.39137112e-07, -2.22318633e-05, -1.77149102e-05,\n",
       "        -1.00788645e-05, -2.01707726e-05, -2.22174475e-05, -1.62681810e-07,\n",
       "        -6.30168823e-06,  1.19297185e-03, -2.97736234e-06,  1.35008407e-04,\n",
       "        -3.24737898e-07, -1.40451169e-06, -6.07613012e-07, -2.22416600e-05,\n",
       "         2.60804343e-04,  1.69474635e-04,  1.28951201e-03, -1.06237063e-06,\n",
       "        -2.09537350e-05, -1.36630226e-07,  2.19883662e-04,  4.25646811e-05,\n",
       "         1.91140886e-05, -1.90776779e-05, -2.08987787e-05,  1.15692600e-04,\n",
       "         1.28800179e-03, -1.97419248e-05]),\n",
       " {'model.mean_module.raw_constant': tensor(0.0010, dtype=torch.float64),\n",
       "  'model.covar_module.raw_lengthscale': tensor([[-1.4504e-05, -2.2025e-06, -1.3378e-06, -1.6873e-05,  1.1129e-03,\n",
       "            1.2697e-03,  5.9912e-04, -4.5611e-06, -3.7786e-06,  9.2503e-04,\n",
       "            9.3091e-04, -5.8963e-07,  5.9111e-04,  1.1348e-03,  8.8492e-04,\n",
       "           -2.1765e-05, -1.4371e-05, -1.8948e-05,  5.2410e-04,  7.5820e-04,\n",
       "            2.5759e-04, -1.8451e-06, -2.2005e-05,  4.0820e-04,  1.1682e-03,\n",
       "           -1.9290e-07,  6.9930e-04, -3.0327e-07,  5.3609e-04,  7.3612e-04,\n",
       "           -8.4305e-06, -3.2865e-07,  6.0662e-05, -3.1301e-06, -1.5433e-07,\n",
       "            6.8042e-04, -2.1967e-05, -2.4669e-06, -8.5347e-06,  1.2181e-03,\n",
       "            1.2962e-03, -6.3881e-07,  2.7890e-04, -2.1543e-05,  9.9819e-04,\n",
       "           -1.3925e-07,  1.1290e-03, -1.8473e-05,  8.1971e-04, -1.9643e-06,\n",
       "           -1.5381e-06, -1.2139e-06, -5.1862e-06,  1.1926e-03,  6.0934e-05,\n",
       "            2.6336e-04,  4.8372e-05, -1.4288e-05, -3.1248e-06, -1.4064e-06,\n",
       "            1.6994e-04,  9.9242e-04,  3.0749e-04, -1.2116e-05, -3.6626e-06,\n",
       "            3.8493e-04, -1.5167e-05, -2.1797e-05, -2.2102e-05,  3.4193e-04,\n",
       "            2.9556e-04, -1.2872e-06,  1.1091e-04,  4.1908e-04,  5.0694e-04,\n",
       "            2.1912e-04,  1.0562e-05, -7.4344e-07,  3.7389e-04,  4.2371e-04,\n",
       "           -7.3540e-06, -2.2043e-05, -2.1995e-05, -1.8739e-05,  1.2783e-03,\n",
       "           -2.2157e-05,  1.2830e-04, -3.2167e-06,  5.3575e-04, -2.8561e-06,\n",
       "           -1.6610e-05,  8.3299e-04,  4.2120e-04,  1.0528e-03,  1.0020e-04,\n",
       "            3.5061e-04, -1.9635e-05, -8.6668e-06, -2.1260e-05,  2.4057e-04,\n",
       "           -6.3584e-07,  4.9973e-04, -2.1718e-05,  1.2694e-03,  9.9896e-04,\n",
       "           -1.9741e-05, -1.3400e-05, -1.9722e-05,  7.5607e-04, -1.9365e-05,\n",
       "            3.7133e-04,  1.2206e-04,  6.9519e-05, -1.0603e-06, -2.5413e-06,\n",
       "            1.0049e-03,  7.3721e-04,  6.1179e-04, -1.7583e-05,  5.7441e-04,\n",
       "            1.1487e-05,  1.0073e-03, -2.0437e-05, -2.0512e-05, -2.8721e-07,\n",
       "           -3.0453e-07, -2.1508e-05,  2.5387e-04, -3.9372e-07, -1.4502e-07,\n",
       "            1.6401e-05,  3.0300e-04, -1.5439e-06, -1.8814e-05,  1.3689e-04,\n",
       "            1.2795e-04, -4.4754e-06, -7.8884e-07, -1.2226e-05, -1.6566e-07,\n",
       "           -1.0401e-05,  9.9538e-04,  6.4828e-04, -9.8299e-06,  5.4344e-04,\n",
       "           -1.2576e-06, -2.0316e-06, -2.1794e-05,  5.6638e-05, -1.8470e-05,\n",
       "            4.9292e-04,  1.0921e-03, -3.3914e-07, -2.2232e-05, -1.7715e-05,\n",
       "           -1.0079e-05, -2.0171e-05, -2.2217e-05, -1.6268e-07, -6.3017e-06,\n",
       "            1.1930e-03, -2.9774e-06,  1.3501e-04, -3.2474e-07, -1.4045e-06,\n",
       "           -6.0761e-07, -2.2242e-05,  2.6080e-04,  1.6947e-04,  1.2895e-03,\n",
       "           -1.0624e-06, -2.0954e-05, -1.3663e-07,  2.1988e-04,  4.2565e-05,\n",
       "            1.9114e-05, -1.9078e-05, -2.0899e-05,  1.1569e-04,  1.2880e-03,\n",
       "           -1.9742e-05]], dtype=torch.float64)})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(gp_fitting)\n",
    "\n",
    "gp_fitting.trainpath_mll_and_grad(gp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b7fa2c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "torch.Size([2000, 1])\n"
     ]
    }
   ],
   "source": [
    "print(gp_model.batch_shape)              # likely: torch.Size([m])\n",
    "# print(gp_model.likelihood.batch_shape)   # same\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "289d4cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature    length_scale        1/length\n",
      "---------------------------------------\n",
      "x40          0.00109253          915.31\n",
      "x169         0.00113738         879.214\n",
      "x179         0.00114776         871.263\n",
      "x84          0.00121692         821.746\n",
      "x5           0.00128142         780.382\n",
      "x103         0.00128342         779.167\n",
      "x39          0.00174723         572.336\n",
      "x160         0.00203155         492.235\n",
      "x53          0.00203666         491.001\n",
      "x24          0.00235697         424.273\n",
      "x13          0.00287948         347.285\n",
      "x46          0.00298052         335.512\n",
      "x4           0.00328218         304.675\n",
      "x151         0.00371711         269.026\n",
      "x93          0.00470109         212.716\n",
      "x121         0.00616329         162.251\n",
      "x115         0.00625022         159.994\n",
      "x104         0.00647535         154.432\n",
      "x44            0.006505         153.728\n",
      "x141         0.00661448         151.184\n",
      "x61          0.00673175          148.55\n",
      "x10          0.00969063         103.193\n",
      "x9            0.0100324         99.6774\n",
      "x14           0.0127054         78.7065\n",
      "x91           0.0172211         58.0682\n",
      "x48           0.0186073         53.7423\n",
      "x19           0.0265757         37.6284\n",
      "x108          0.0269032         37.1702\n",
      "x116          0.0299857         33.3493\n",
      "x29           0.0301738         33.1413\n",
      "x26           0.0372467         26.8481\n",
      "x35           0.0414681         24.1149\n",
      "x142          0.0497293         20.1089\n",
      "x117          0.0610233         16.3872\n",
      "x6            0.0654892         15.2697\n",
      "x12           0.0684692         14.6051\n",
      "x119          0.0751119         13.3135\n",
      "x144          0.0890868          11.225\n",
      "x28           0.0927467         10.7821\n",
      "x88           0.0929211         10.7618\n",
      "x18            0.099035         10.0974\n",
      "x74            0.108745         9.19583\n",
      "x101            0.11309         8.84248\n",
      "x150           0.117344         8.52198\n",
      "x79            0.170289         5.87236\n",
      "x92            0.172584         5.79427\n",
      "x73             0.17455         5.72901\n",
      "x23            0.184982         5.40592\n",
      "x65            0.209382         4.77596\n",
      "x78            0.222036         4.50378\n",
      "x110           0.225077         4.44293\n",
      "x95            0.251256         3.98001\n",
      "x69            0.263107         3.80074\n",
      "x62            0.315986          3.1647\n",
      "x131           0.323641         3.08984\n",
      "x70            0.336748         2.96958\n",
      "x42            0.368172         2.71612\n",
      "x55            0.400274         2.49829\n",
      "x167           0.405836         2.46405\n",
      "x20            0.412951          2.4216\n",
      "x127            0.42136         2.37327\n",
      "x99            0.452961         2.20769\n",
      "x173           0.507502         1.97044\n",
      "x75            0.509653         1.96212\n",
      "x60            0.673762          1.4842\n",
      "x168           0.675604         1.48016\n",
      "x134            0.82174         1.21693\n",
      "x162           0.831422         1.20276\n",
      "x86            0.867143         1.15321\n",
      "x135           0.869079         1.15064\n",
      "x111           0.902271         1.10831\n",
      "x178           0.940231         1.06357\n",
      "x72            0.970241         1.03067\n",
      "x94              1.0427         0.95905\n",
      "x112            1.30338        0.767234\n",
      "x54             1.39575         0.71646\n",
      "x32             1.39886        0.714867\n",
      "x148            1.44631        0.691412\n",
      "x56             1.55332        0.643781\n",
      "x174            1.63757        0.610661\n",
      "x175            2.09421        0.477507\n",
      "x130            2.16513        0.461866\n",
      "x120            2.30849        0.433183\n",
      "x76             2.33799        0.427718\n",
      "x11             2.78422        0.359167\n",
      "x16             3.87626        0.257981\n",
      "x90             4.22385        0.236751\n",
      "x47             4.62285        0.216317\n",
      "x17             4.75127         0.21047\n",
      "x176             4.7889        0.208816\n",
      "x123            5.31986        0.187975\n",
      "x43             5.97974        0.167231\n",
      "x102             6.1544        0.162485\n",
      "x15             6.20732          0.1611\n",
      "x81             6.62565        0.150929\n",
      "x85             6.91382        0.144638\n",
      "x157             7.1839          0.1392\n",
      "x166            7.56311        0.132221\n",
      "x153            7.75179        0.129003\n",
      "x68             8.44174        0.118459\n",
      "x22             8.75894        0.114169\n",
      "x82             8.78799        0.113792\n",
      "x36             8.86944        0.112747\n",
      "x67             9.30777        0.107437\n",
      "x147            9.31438        0.107361\n",
      "x126            9.95198        0.100482\n",
      "x98             10.4543       0.0956543\n",
      "x171            11.0427       0.0905577\n",
      "x177             11.146       0.0897181\n",
      "x122            11.9995        0.083337\n",
      "x156            12.4874       0.0800805\n",
      "x180            13.2752       0.0753287\n",
      "x105            13.2774        0.075316\n",
      "x107            13.3113       0.0751242\n",
      "x96             13.4728       0.0742235\n",
      "x109            13.9778       0.0715419\n",
      "x133            15.0285       0.0665401\n",
      "x83             15.1763       0.0658921\n",
      "x149            15.7076       0.0636636\n",
      "x154            17.2684       0.0579092\n",
      "x118            17.5535       0.0569686\n",
      "x3              19.1532       0.0522105\n",
      "x66             23.6037       0.0423662\n",
      "x0              25.6265       0.0390221\n",
      "x57             26.3296       0.0379801\n",
      "x106            29.4812       0.0339199\n",
      "x138            34.4256       0.0290481\n",
      "x63             34.9438       0.0286174\n",
      "x140            44.6229         0.02241\n",
      "x155            46.8586       0.0213408\n",
      "x143            48.6983       0.0205346\n",
      "x97             58.8867       0.0169818\n",
      "x38              60.243       0.0165995\n",
      "x30             61.3464       0.0163009\n",
      "x80             74.8291       0.0133638\n",
      "x159            93.1035       0.0107407\n",
      "x52              121.75      0.00821356\n",
      "x7              144.761      0.00690793\n",
      "x136            148.477      0.00673504\n",
      "x8              185.733      0.00538406\n",
      "x64             193.472      0.00516871\n",
      "x87             229.039      0.00436607\n",
      "x33             237.242       0.0042151\n",
      "x58             237.767       0.0042058\n",
      "x161            253.021      0.00395224\n",
      "x89             266.875      0.00374708\n",
      "x114            309.686      0.00322907\n",
      "x37             321.579      0.00310966\n",
      "x1              371.007      0.00269537\n",
      "x146             410.51        0.002436\n",
      "x49             428.146      0.00233565\n",
      "x21             462.834       0.0021606\n",
      "x132            576.937      0.00173329\n",
      "x50             579.608       0.0017253\n",
      "x59             646.904      0.00154582\n",
      "x164            647.955      0.00154332\n",
      "x2              687.682      0.00145416\n",
      "x71             720.797      0.00138735\n",
      "x145            741.493      0.00134863\n",
      "x51             774.164      0.00129172\n",
      "x170            909.894      0.00109903\n",
      "x113             912.09      0.00109638\n",
      "x137            1300.93     0.000768682\n",
      "x77             1396.24     0.000716211\n",
      "x41             1671.94     0.000598108\n",
      "x100            1681.17     0.000594823\n",
      "x165            1774.03     0.000563688\n",
      "x128            2953.56     0.000338575\n",
      "x152            3514.39     0.000284544\n",
      "x31             3645.02     0.000274347\n",
      "x163            3696.09     0.000270556\n",
      "x125            3982.16      0.00025112\n",
      "x27              4001.3     0.000249919\n",
      "x124            4261.66      0.00023465\n",
      "x25             6741.66     0.000148331\n",
      "x139            8025.56     0.000124602\n",
      "x158            8193.54     0.000122047\n",
      "x34              8702.1     0.000114915\n",
      "x129             9342.2     0.000107041\n",
      "x45             9784.99     0.000102197\n",
      "x172             9998.7     0.000100013\n"
     ]
    }
   ],
   "source": [
    "bo.gp_ = gp\n",
    "bo.report_ard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf5f7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.082458700830832"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_fitting._init_lengthscales_vanilla_bo_(gp_model, seed=1)\n",
    "gp_fitting.compute_likelihood(gp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7510d06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective=2.875805\n",
      "objective=3.098573\n",
      "objective=25.371367\n",
      "objective=2.109362\n",
      "objective=3.744775\n",
      "objective=2.525977\n",
      "objective=2.167100\n",
      "objective=16.499809\n",
      "objective=2.092994\n",
      "objective=19.242168\n",
      "objective=2.523432\n",
      "objective=11.540376\n",
      "objective=3.055659\n",
      "objective=10.225184\n",
      "objective=2.121414\n",
      "objective=19.152492\n",
      "objective=4.017143\n",
      "objective=2.473732\n",
      "objective=3.294603\n",
      "objective=15.735495\n",
      "objective=11.653039\n",
      "objective=7.404815\n",
      "objective=2.196977\n",
      "objective=2.627395\n",
      "objective=19.583467\n",
      "objective=3.255722\n",
      "objective=34.833438\n",
      "objective=4.146297\n",
      "objective=14.062797\n",
      "objective=3.903402\n",
      "objective=9.279691\n",
      "objective=2.363375\n",
      "objective=2.880189\n",
      "objective=19.285920\n",
      "objective=3.310895\n",
      "objective=6.553866\n",
      "objective=2.817738\n",
      "objective=12.584274\n",
      "objective=4.164663\n",
      "objective=2.165693\n",
      "objective=7.770820\n",
      "objective=2.145283\n",
      "objective=7.717736\n",
      "objective=2.084759\n",
      "objective=10.089458\n",
      "objective=40.033589\n",
      "objective=5.025263\n",
      "objective=2.154811\n",
      "objective=13.936337\n",
      "objective=2.326117\n",
      "objective=24.493775\n",
      "objective=3.029107\n",
      "objective=5.681541\n",
      "objective=16.669127\n",
      "objective=3.755229\n",
      "objective=16.349470\n",
      "objective=3.101094\n",
      "objective=2.288217\n",
      "objective=40.277078\n",
      "objective=2.682915\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m reload(gp_fitting)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# ----------------------------- usage ---------------------------------\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# gp is your model (e.g., SingleTaskGP) already constructed with data.\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m gp, info \u001b[38;5;241m=\u001b[39m \u001b[43mgp_fitting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_mll\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgp_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_lengthscales_with_vanilla_bo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(info)\n",
      "File \u001b[0;32m/data/antonovk/FewShotCVRP/FewShotCVRP/bo/gp_fitting.py:502\u001b[0m, in \u001b[0;36moptimize_mll\u001b[0;34m(gp, sigma0, maxfevals, ls_bounds, os_bounds, noise_bounds, mean_bounds, period_bounds, seed, do_refine_with_fit, init_lengthscales_with_vanilla_bo, verbose)\u001b[0m\n\u001b[1;32m    494\u001b[0m f \u001b[38;5;241m=\u001b[39m _objective_factory(gp, items, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m    495\u001b[0m opts \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbounds\u001b[39m\u001b[38;5;124m\"\u001b[39m: [lo\u001b[38;5;241m.\u001b[39mtolist(), hi\u001b[38;5;241m.\u001b[39mtolist()],  \u001b[38;5;66;03m# bounds in z-space\u001b[39;00m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m,\n\u001b[1;32m    501\u001b[0m }\n\u001b[0;32m--> 502\u001b[0m xbest, fbest, \u001b[38;5;241m*\u001b[39m_ \u001b[38;5;241m=\u001b[39m \u001b[43mcma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# runs CMA-ES\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;66;03m# set best and (optionally) refine with gradient-based fit\u001b[39;00m\n\u001b[1;32m    505\u001b[0m set_from_z(gp, items, xbest)\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/cma/evolution_strategy.py:4515\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(objective_function, x0, sigma0, *posargs, **kwargs)\u001b[0m\n\u001b[1;32m   4512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m   4513\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m es\u001b[38;5;241m.\u001b[39mstop():  \u001b[38;5;66;03m# iteration loop\u001b[39;00m\n\u001b[1;32m   4514\u001b[0m         \u001b[38;5;66;03m# X, fit = eval_in_parallel(lambda: es.ask(1)[0], es.popsize, args, repetitions=noisehandler.evaluations-1)\u001b[39;00m\n\u001b[0;32m-> 4515\u001b[0m         X, fit \u001b[38;5;241m=\u001b[39m \u001b[43mes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mask_and_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparallel_objective\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobjective_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4516\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4517\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mevaluations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnoisehandler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4518\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmedian\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4519\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mparallel_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel_objective\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# treats NaN with resampling if not parallel_mode\u001b[39;00m\n\u001b[1;32m   4520\u001b[0m         \u001b[38;5;66;03m# TODO: check args and in case use args=(noisehandler.evaluations, )\u001b[39;00m\n\u001b[1;32m   4522\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m11\u001b[39m \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m opts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvv\u001b[39m\u001b[38;5;124m'\u001b[39m]:  \u001b[38;5;66;03m# inject a solution\u001b[39;00m\n\u001b[1;32m   4523\u001b[0m             \u001b[38;5;66;03m# use option check_point = [0]\u001b[39;00m\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/cma/evolution_strategy.py:1964\u001b[0m, in \u001b[0;36mCMAEvolutionStrategy.ask_and_eval\u001b[0;34m(self, func, args, gradf, number, xmean, sigma_fac, evaluations, aggregation, kappa, parallel_mode)\u001b[0m\n\u001b[1;32m   1960\u001b[0m     length_normalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmahalanobis_norm(x \u001b[38;5;241m-\u001b[39m xmean)  \u001b[38;5;66;03m# self.const.chiN < N**0.5, the constant here is irrelevant (absorbed by kappa)\u001b[39;00m\n\u001b[1;32m   1961\u001b[0m     \u001b[38;5;66;03m# print(self.N**0.5 / self.mahalanobis_norm(x - xmean))\u001b[39;00m\n\u001b[1;32m   1962\u001b[0m     \u001b[38;5;66;03m# self.more_to_write += [length_normalizer * 1e-3, length_normalizer * self.mahalanobis_norm(x - xmean) * 1e2]\u001b[39;00m\n\u001b[0;32m-> 1964\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m kappa \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \\\n\u001b[1;32m   1965\u001b[0m     func(xmean \u001b[38;5;241m+\u001b[39m kappa \u001b[38;5;241m*\u001b[39m length_normalizer \u001b[38;5;241m*\u001b[39m (x \u001b[38;5;241m-\u001b[39m xmean),\n\u001b[1;32m   1966\u001b[0m          \u001b[38;5;241m*\u001b[39margs)  \u001b[38;5;66;03m# CAVEAT: kappa != 1 is incompatible with integer variables\u001b[39;00m\n\u001b[1;32m   1967\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_feasible(x, f) \u001b[38;5;129;01mand\u001b[39;00m evaluations \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1968\u001b[0m     f \u001b[38;5;241m=\u001b[39m aggregation([f] \u001b[38;5;241m+\u001b[39m [(func(x, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;28;01mif\u001b[39;00m kappa \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m   1969\u001b[0m                             func(xmean \u001b[38;5;241m+\u001b[39m kappa \u001b[38;5;241m*\u001b[39m length_normalizer \u001b[38;5;241m*\u001b[39m (x \u001b[38;5;241m-\u001b[39m xmean), \u001b[38;5;241m*\u001b[39margs))\n\u001b[1;32m   1970\u001b[0m                            \u001b[38;5;28;01mfor\u001b[39;00m _i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mint\u001b[39m(evaluations \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m))])\n",
      "File \u001b[0;32m/data/antonovk/FewShotCVRP/FewShotCVRP/bo/gp_fitting.py:443\u001b[0m, in \u001b[0;36m_objective_factory.<locals>.f\u001b[0;34m(z)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mf\u001b[39m(z):\n\u001b[1;32m    442\u001b[0m     set_from_z(gp, items, z)\n\u001b[0;32m--> 443\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[43m_trainpath_mll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgp\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# minimize -MLL\u001b[39;00m\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(val):\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1e100\u001b[39m\n",
      "File \u001b[0;32m/data/antonovk/FewShotCVRP/FewShotCVRP/bo/gp_fitting.py:198\u001b[0m, in \u001b[0;36m_trainpath_mll\u001b[0;34m(gp)\u001b[0m\n\u001b[1;32m    195\u001b[0m     was_m, was_l \u001b[38;5;241m=\u001b[39m gp\u001b[38;5;241m.\u001b[39mtraining, gp\u001b[38;5;241m.\u001b[39mlikelihood\u001b[38;5;241m.\u001b[39mtraining\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 198\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(torch\u001b[38;5;241m.\u001b[39msum(\u001b[43mmll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtr\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     gp\u001b[38;5;241m.\u001b[39mtrain(was_m)\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/gpytorch/module.py:82\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, Distribution, LinearOperator]:\n\u001b[0;32m---> 82\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py:82\u001b[0m, in \u001b[0;36mExactMarginalLogLikelihood.forward\u001b[0;34m(self, function_dist, target, *params, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN observation policy \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfill\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not supported by ExactMarginalLogLikelihood!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Get the log prob of the marginal distribution\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_other_terms(res, params)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# Scale by the amount of data we have\u001b[39;00m\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/gpytorch/distributions/multivariate_normal.py:228\u001b[0m, in \u001b[0;36mMultivariateNormal.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03mSee :py:meth:`torch.distributions.Distribution.log_prob\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03m<torch.distributions.distribution.Distribution.log_prob>`.\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m settings\u001b[38;5;241m.\u001b[39mfast_computations\u001b[38;5;241m.\u001b[39mlog_prob\u001b[38;5;241m.\u001b[39moff():\n\u001b[0;32m--> 228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_args:\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_sample(value)\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/torch/distributions/multivariate_normal.py:255\u001b[0m, in \u001b[0;36mMultivariateNormal.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_sample(value)\n\u001b[1;32m    254\u001b[0m diff \u001b[38;5;241m=\u001b[39m value \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc\n\u001b[0;32m--> 255\u001b[0m M \u001b[38;5;241m=\u001b[39m _batch_mahalanobis(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unbroadcasted_scale_tril\u001b[49m, diff)\n\u001b[1;32m    256\u001b[0m half_log_det \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unbroadcasted_scale_tril\u001b[38;5;241m.\u001b[39mdiagonal(dim1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, dim2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mlog()\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    258\u001b[0m )\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_shape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mpi) \u001b[38;5;241m+\u001b[39m M) \u001b[38;5;241m-\u001b[39m half_log_det\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/gpytorch/distributions/multivariate_normal.py:88\u001b[0m, in \u001b[0;36mMultivariateNormal._unbroadcasted_scale_tril\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_unbroadcasted_scale_tril\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mislazy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__unbroadcasted_scale_tril \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;66;03m# cache root decoposition\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m         ust \u001b[38;5;241m=\u001b[39m to_dense(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_covariance_matrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__unbroadcasted_scale_tril \u001b[38;5;241m=\u001b[39m ust\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__unbroadcasted_scale_tril\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/linear_operator/operators/_linear_operator.py:1311\u001b[0m, in \u001b[0;36mLinearOperator.cholesky\u001b[0;34m(self, upper)\u001b[0m\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;129m@_implements\u001b[39m(torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mcholesky)\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcholesky\u001b[39m(\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;28mself\u001b[39m: Float[LinearOperator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*batch N N\u001b[39m\u001b[38;5;124m\"\u001b[39m], upper: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Float[LinearOperator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*batch N N\u001b[39m\u001b[38;5;124m\"\u001b[39m]:  \u001b[38;5;66;03m# returns TriangularLinearOperator\u001b[39;00m\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;124;03m    Cholesky-factorizes the LinearOperator.\u001b[39;00m\n\u001b[1;32m   1307\u001b[0m \n\u001b[1;32m   1308\u001b[0m \u001b[38;5;124;03m    :param upper: Upper triangular or lower triangular factor (default: False).\u001b[39;00m\n\u001b[1;32m   1309\u001b[0m \u001b[38;5;124;03m    :return: Cholesky factor (lower or upper triangular)\u001b[39;00m\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1311\u001b[0m     chol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m upper:\n\u001b[1;32m   1313\u001b[0m         chol \u001b[38;5;241m=\u001b[39m chol\u001b[38;5;241m.\u001b[39m_transpose_nonbatch()\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/linear_operator/utils/memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m kwargs_pkl \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mdumps(kwargs)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_in_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl):\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _add_to_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_from_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/linear_operator/operators/_linear_operator.py:528\u001b[0m, in \u001b[0;36mLinearOperator._cholesky\u001b[0;34m(self, upper)\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TriangularLinearOperator(evaluated_mat\u001b[38;5;241m.\u001b[39mclamp_min(\u001b[38;5;241m0.0\u001b[39m)\u001b[38;5;241m.\u001b[39msqrt())\n\u001b[1;32m    527\u001b[0m \u001b[38;5;66;03m# contiguous call is necessary here\u001b[39;00m\n\u001b[0;32m--> 528\u001b[0m cholesky \u001b[38;5;241m=\u001b[39m \u001b[43mpsd_safe_cholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluated_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupper\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TriangularLinearOperator(cholesky, upper\u001b[38;5;241m=\u001b[39mupper)\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/linear_operator/utils/cholesky.py:65\u001b[0m, in \u001b[0;36mpsd_safe_cholesky\u001b[0;34m(A, upper, out, jitter, max_tries)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpsd_safe_cholesky\u001b[39m(A, upper\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, jitter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, max_tries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     51\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the Cholesky decomposition of A. If A is only p.s.d, add a small jitter to the diagonal.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m        :attr:`A` (Tensor):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m            Number of attempts (with successively increasing jitter) to make before raising an error.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m     L \u001b[38;5;241m=\u001b[39m \u001b[43m_psd_safe_cholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjitter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjitter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m upper:\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/linear_operator/utils/cholesky.py:20\u001b[0m, in \u001b[0;36m_psd_safe_cholesky\u001b[0;34m(A, out, jitter, max_tries)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m     out \u001b[38;5;241m=\u001b[39m (out, torch\u001b[38;5;241m.\u001b[39mempty(A\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint32, device\u001b[38;5;241m=\u001b[39mout\u001b[38;5;241m.\u001b[39mdevice))\n\u001b[0;32m---> 20\u001b[0m L, info \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcholesky_ex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m settings\u001b[38;5;241m.\u001b[39mtrace_mode\u001b[38;5;241m.\u001b[39mon() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39many(info):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m L\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import FewShotCVRP.bo.gp_fitting as gp_fitting\n",
    "\n",
    "reload(gp_fitting)\n",
    "\n",
    "# ----------------------------- usage ---------------------------------\n",
    "# gp is your model (e.g., SingleTaskGP) already constructed with data.\n",
    "gp, info = gp_fitting.optimize_mll(\n",
    "    gp_model, seed=1, verbose=True, init_lengthscales_with_vanilla_bo=True\n",
    ")\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0dfd22d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m gp_model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      7\u001b[0m gp_model\u001b[38;5;241m.\u001b[39mlikelihood\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 8\u001b[0m \u001b[43mfit_gpytorch_mll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmll\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# LBFGS-B refinement\u001b[39;00m\n\u001b[1;32m      9\u001b[0m gp_model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     10\u001b[0m gp_model\u001b[38;5;241m.\u001b[39mlikelihood\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/botorch/fit.py:115\u001b[0m, in \u001b[0;36mfit_gpytorch_mll\u001b[0;34m(mll, closure, optimizer, closure_kwargs, optimizer_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# defer to per-method defaults\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m optimizer\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFitGPyTorchMLL\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmll\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmll\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlikelihood\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmll\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclosure_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/botorch/utils/dispatcher.py:95\u001b[0m, in \u001b[0;36mDispatcher.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(types\u001b[38;5;241m=\u001b[39mtypes)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MDNotImplementedError:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# Traverses registered methods in order, yields whenever a match is found\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     funcs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_iter(\u001b[38;5;241m*\u001b[39mtypes)\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/botorch/fit.py:215\u001b[0m, in \u001b[0;36m_fit_fallback\u001b[0;34m(mll, _, __, closure, optimizer, closure_kwargs, optimizer_kwargs, max_attempts, pick_best_of_all_attempts, warning_handler, caught_exception_types, **ignore)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m catch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m warning_list:\n\u001b[1;32m    214\u001b[0m     simplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malways\u001b[39m\u001b[38;5;124m\"\u001b[39m, category\u001b[38;5;241m=\u001b[39mOptimizationWarning)\n\u001b[0;32m--> 215\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;66;03m# Resolve warnings and determine whether or not to retry\u001b[39;00m\n\u001b[1;32m    218\u001b[0m success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/botorch/optim/fit.py:94\u001b[0m, in \u001b[0;36mfit_gpytorch_mll_scipy\u001b[0;34m(mll, parameters, bounds, closure, closure_kwargs, method, options, callback, timeout_sec)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     closure \u001b[38;5;241m=\u001b[39m partial(closure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mclosure_kwargs)\n\u001b[0;32m---> 94\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mscipy_minimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_sec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_sec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [OptimizationStatus\u001b[38;5;241m.\u001b[39mSUCCESS, OptimizationStatus\u001b[38;5;241m.\u001b[39mSTOPPED]:\n\u001b[1;32m    104\u001b[0m     warn(\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`scipy_minimize` terminated with status \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, displaying\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m original message from `scipy.optimize.minimize`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    107\u001b[0m         OptimizationWarning,\n\u001b[1;32m    108\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    109\u001b[0m     )\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/botorch/optim/core.py:115\u001b[0m, in \u001b[0;36mscipy_minimize\u001b[0;34m(closure, parameters, bounds, callback, x0, method, options, timeout_sec)\u001b[0m\n\u001b[1;32m    107\u001b[0m         result \u001b[38;5;241m=\u001b[39m OptimizationResult(\n\u001b[1;32m    108\u001b[0m             step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mnext\u001b[39m(call_counter),\n\u001b[1;32m    109\u001b[0m             fval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(wrapped_closure(x)[\u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m    110\u001b[0m             status\u001b[38;5;241m=\u001b[39mOptimizationStatus\u001b[38;5;241m.\u001b[39mRUNNING,\n\u001b[1;32m    111\u001b[0m             runtime\u001b[38;5;241m=\u001b[39mmonotonic() \u001b[38;5;241m-\u001b[39m start_time,\n\u001b[1;32m    112\u001b[0m         )\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m callback(parameters, result)  \u001b[38;5;66;03m# pyre-ignore [29]\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m raw \u001b[38;5;241m=\u001b[39m \u001b[43mminimize_with_timeout\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrapped_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrapped_closure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp_float64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds_np\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrapped_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_sec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_sec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# Post-processing and outcome handling\u001b[39;00m\n\u001b[1;32m    127\u001b[0m wrapped_closure\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m asarray(raw\u001b[38;5;241m.\u001b[39mx)  \u001b[38;5;66;03m# set parameter state to optimal values\u001b[39;00m\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/botorch/optim/utils/timeout.py:86\u001b[0m, in \u001b[0;36mminimize_with_timeout\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options, timeout_sec)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;66;03m# To prevent slowdowns after scipy 1.15.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;66;03m# See https://github.com/scipy/scipy/issues/22438.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m threadpool_limits(limits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, user_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblas\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 86\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m            \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhessp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhessp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrapped_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OptimizationTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    101\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimization timed out after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mruntime\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/scipy/optimize/_minimize.py:738\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    735\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    736\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 738\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    741\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    742\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py:441\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    433\u001b[0m _lbfgsb\u001b[38;5;241m.\u001b[39msetulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr, pgtol, wa,\n\u001b[1;32m    434\u001b[0m                iwa, task, lsave, isave, dsave, maxls, ln_task)\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 441\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    444\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:344\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x(x)\n\u001b[0;32m--> 344\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:295\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 295\u001b[0m         fx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m fx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_f:\n\u001b[1;32m    297\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:21\u001b[0m, in \u001b[0;36m_wrapper_fun.<locals>.wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     17\u001b[0m ncalls[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/scipy/optimize/_optimize.py:80\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     79\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/scipy/optimize/_optimize.py:74\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 74\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/botorch/optim/closures/core.py:83\u001b[0m, in \u001b[0;36mNdarrayOptimizationClosure.__call__\u001b[0;34m(self, state, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m state\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 83\u001b[0m     value_tensor, grad_tensors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     value \u001b[38;5;241m=\u001b[39m as_ndarray(values\u001b[38;5;241m=\u001b[39mvalue_tensor, dtype\u001b[38;5;241m=\u001b[39mnp_float64)\n\u001b[1;32m     85\u001b[0m     grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_gradient_ndarray()\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/botorch/optim/closures/core.py:46\u001b[0m, in \u001b[0;36mForwardBackwardClosure.__call__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m zero_grad_ctx(parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters):\n\u001b[1;32m     45\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m---> 46\u001b[0m     \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(param\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value, grads\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/torch/_tensor.py:647\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    639\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    640\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    645\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    646\u001b[0m     )\n\u001b[0;32m--> 647\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/torch/autograd/__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/antonovk/venv-cvrp/lib/python3.10/site-packages/torch/autograd/graph.py:829\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "\n",
    "\n",
    "mll = ExactMarginalLogLikelihood(gp_model.likelihood, gp_model)\n",
    "gp_model.train()\n",
    "gp_model.likelihood.train()\n",
    "fit_gpytorch_mll(mll)  # LBFGS-B refinement\n",
    "gp_model.eval()\n",
    "gp_model.likelihood.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b3d7db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.7982353333282004"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import FewShotCVRP.bo.gp_fitting as gp_fitting\n",
    "\n",
    "reload(gp_fitting)\n",
    "\n",
    "gp_fitting.compute_likelihood(gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65e8561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.0578, dtype=torch.float64)\n",
      "tensor(-2.0578, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "gp_model.train()\n",
    "gp_model.likelihood.train()    \n",
    "mll = ExactMarginalLogLikelihood(gp_model.likelihood, gp_model)\n",
    "Xtr = gp_model.train_inputs[0]\n",
    "Ytr = gp_model.train_targets\n",
    "with torch.no_grad():\n",
    "    ans = mll(gp_model(Xtr), Ytr)\n",
    "gp_model.eval()\n",
    "gp_model.likelihood.eval()\n",
    "print(ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e26b958c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 181])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FixedNoiseGaussianLikelihood(\n",
       "  (noise_covar): FixedGaussianNoise()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_model.train()\n",
    "gp_model.likelihood.train()\n",
    "Xtr = gp_model.train_inputs[0]\n",
    "Ytr = gp_model.train_targets\n",
    "print(Xtr.shape)\n",
    "gp_model.eval()\n",
    "gp_model.likelihood.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a9b7b068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['precomputed_DoEs.joblib']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import joblib\n",
    "\n",
    "precomputed = {}\n",
    "\n",
    "\n",
    "def process_arrays_file(pth):\n",
    "    arrays_file = np.load(Path(pth))\n",
    "    arrays = {k: arrays_file[k] for k in arrays_file.files}\n",
    "    pattern = r\"X-[^/]+\"\n",
    "    instance_name = re.search(pattern, pth).group(0)\n",
    "    instance_name += \".xml\"\n",
    "    precomputed.update({instance_name: arrays})\n",
    "    return precomputed\n",
    "\n",
    "\n",
    "process_arrays_file(\n",
    "    \"../outputs/2025-09-15-20h59m23s/per-instance-param-control/X-n101-k25/rs-final/arrays.npz\"\n",
    ")\n",
    "process_arrays_file(\n",
    "    \"../outputs/2025-09-15-21h14m37s/per-instance-param-control/X-n209-k16/rs-final/arrays.npz\"\n",
    ")\n",
    "process_arrays_file(\n",
    "    \"../outputs/2025-09-15-21h40m10s/per-instance-param-control/X-n641-k35/rs-final/arrays.npz\"\n",
    ")\n",
    "process_arrays_file(\n",
    "    \"../outputs/2025-09-15-22h48m21s/per-instance-param-control/X-n1001-k43/rs-final/arrays.npz\"\n",
    ")\n",
    "joblib.dump(precomputed, 'precomputed_DoEs.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8dc7f6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_dict = joblib.load('precomputed_DoEs.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8f3b058d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([{'X_': array([[ 0.86007077,  1.45272467, -1.48796375, ...,  0.35721421,\n",
       "         0.61754097,  0.05820011],\n",
       "       [-0.87097308, -0.00480234,  0.51726191, ..., -0.99869247,\n",
       "        -1.03821044, -0.04096668],\n",
       "       [-0.30916752,  0.40826724, -0.57384548, ..., -0.25000843,\n",
       "        -0.46809533,  0.45030411],\n",
       "       ...,\n",
       "       [-0.01249481, -0.81147109, -0.24491854, ...,  0.71032993,\n",
       "        -0.90756352,  0.12245068],\n",
       "       [-1.15535509,  1.19621295,  0.21678429, ...,  0.58930993,\n",
       "        -0.29182482, -0.49981245],\n",
       "       [ 1.15644719, -0.32337707, -0.79451487, ..., -1.21086954,\n",
       "         0.74074518,  0.51502744]], shape=(2000, 181)), 'y_': array([33801., 34951., 33873., ..., 46446., 45749., 45887.], shape=(2000,)), 'bounds': array([[-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-0.51639777,  0.51639777]])}, {'X_': array([[ 0.86007077,  1.45272467, -1.48796375, ...,  0.35721421,\n",
       "         0.61754097,  0.05820011],\n",
       "       [-0.87097308, -0.00480234,  0.51726191, ..., -0.99869247,\n",
       "        -1.03821044, -0.04096668],\n",
       "       [-0.30916752,  0.40826724, -0.57384548, ..., -0.25000843,\n",
       "        -0.46809533,  0.45030411],\n",
       "       ...,\n",
       "       [-0.01249481, -0.81147109, -0.24491854, ...,  0.71032993,\n",
       "        -0.90756352,  0.12245068],\n",
       "       [-1.15535509,  1.19621295,  0.21678429, ...,  0.58930993,\n",
       "        -0.29182482, -0.49981245],\n",
       "       [ 1.15644719, -0.32337707, -0.79451487, ..., -1.21086954,\n",
       "         0.74074518,  0.51502744]], shape=(2000, 181)), 'y_': array([66820., 76554., 68720., ..., 94381., 91868., 96046.], shape=(2000,)), 'bounds': array([[-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-0.51639777,  0.51639777]])}, {'X_': array([[ 0.86007077,  1.45272467, -1.48796375, ...,  0.35721421,\n",
       "         0.61754097,  0.05820011],\n",
       "       [-0.87097308, -0.00480234,  0.51726191, ..., -0.99869247,\n",
       "        -1.03821044, -0.04096668],\n",
       "       [-0.30916752,  0.40826724, -0.57384548, ..., -0.25000843,\n",
       "        -0.46809533,  0.45030411],\n",
       "       ...,\n",
       "       [-0.01249481, -0.81147109, -0.24491854, ...,  0.71032993,\n",
       "        -0.90756352,  0.12245068],\n",
       "       [-1.15535509,  1.19621295,  0.21678429, ...,  0.58930993,\n",
       "        -0.29182482, -0.49981245],\n",
       "       [ 1.15644719, -0.32337707, -0.79451487, ..., -1.21086954,\n",
       "         0.74074518,  0.51502744]], shape=(2000, 181)), 'y_': array([267949., 229738., 228621., ..., 267913., 274422., 272084.],\n",
       "      shape=(2000,)), 'bounds': array([[-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-0.51639777,  0.51639777]])}, {'X_': array([[ 0.86007077,  1.45272467, -1.48796375, ...,  0.35721421,\n",
       "         0.61754097,  0.05820011],\n",
       "       [-0.87097308, -0.00480234,  0.51726191, ..., -0.99869247,\n",
       "        -1.03821044, -0.04096668],\n",
       "       [-0.30916752,  0.40826724, -0.57384548, ..., -0.25000843,\n",
       "        -0.46809533,  0.45030411],\n",
       "       ...,\n",
       "       [-0.01249481, -0.81147109, -0.24491854, ...,  0.71032993,\n",
       "        -0.90756352,  0.12245068],\n",
       "       [-1.15535509,  1.19621295,  0.21678429, ...,  0.58930993,\n",
       "        -0.29182482, -0.49981245],\n",
       "       [ 1.15644719, -0.32337707, -0.79451487, ..., -1.21086954,\n",
       "         0.74074518,  0.51502744]], shape=(2000, 181)), 'y_': array([426187., 385180., 371077., ..., 428425., 439633., 432513.],\n",
       "      shape=(2000,)), 'bounds': array([[-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-1.54919338,  1.54919338],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-0.63245553,  0.63245553],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-1.26491106,  1.26491106],\n",
       "       [-0.51639777,  0.51639777]])}])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0417d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "precomputed = {\n",
    "    \"instance_name_1\": {\n",
    "        \"X_\": np.array([[0.1, 0.2], [0.1, 0.3]]),\n",
    "        \"y_\": np.array([1.0, 2.0]),\n",
    "    },\n",
    "    \"instance_name_2\": {\n",
    "        \"X_\": np.array([[0.1, 0.2], [0.1, 0.3]]),\n",
    "        \"y_\": np.array([10.0, 20.0]),\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3377999f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2,3,4])[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
